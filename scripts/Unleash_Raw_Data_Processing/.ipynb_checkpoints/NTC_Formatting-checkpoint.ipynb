{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cdc7bd8-8fac-427b-988f-3b3326682475",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; margin-left: 0em; font-weight: bold; font-size: 20px; font-family: TimesNewRoman; color: skyblue\">\n",
    "    TIME SERIES DATA PROCESSING\n",
    "    <br>\n",
    "    NET TRANSFER CAPACITY\n",
    "<div style=\"text-align: center; margin-left: 0em; font-weight: bold; font-size: 18px; font-family: TimesNewRoman; color: skyblue\">\n",
    "    Main Formatting Notebook\n",
    "</div>\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color: skyblue\">\n",
    "Each part of the following script was used to process the raw data for the Net Transfer Capacity Time Series Raw Data for all the european countries of the Dispa-SET_Unleash project.\n",
    "<br>\n",
    "Read explanation text cells to follow and understand all the process until final results were got stept by step.\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 18px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    1. Notebook Set Up\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    Importing needed libraries\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15d1e5b-c9ca-4b73-9460-774737b12275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from entsoe import EntsoePandasClient\n",
    "from entsoe.exceptions import NoMatchingDataError  # Ensure this line is included\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from pytz import timezone, utc\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2527fc9-cfed-43fe-aa51-961836c9ad31",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 18px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    2. Dispa-SET_Unleash Folder Path\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    Determinning dynamically the zone_folder_path based on the location of the \"Dispa-SET_Unleash\" folder relative to the current working directory.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "If the \"Dispa-SET_Unleash\" folder is copied to a different machine or location, the dispaSET_unleash_folder_path variable will automatically adjust accordingly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e5e9326-9444-4ddd-8955-bbceecba40ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispaSET_unleash_folder_name: Dispa-SET_Unleash\n",
      "dispaSET_unleash_folder_path: /home/ray/Dispa-SET_Unleash\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Navigate to the parent directory of \"Dispa-SET_Unleash\"\n",
    "dispaSET_unleash_parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "# Get the path to the \"Dispa-SET_Unleash\" folder\n",
    "dispaSET_unleash_folder_path = os.path.dirname(dispaSET_unleash_parent_directory)\n",
    "\n",
    "# Construct the dispaSET_unleash_folder_name variable\n",
    "dispaSET_unleash_folder_name = os.path.basename(dispaSET_unleash_folder_path)\n",
    "\n",
    "print(\"dispaSET_unleash_folder_name:\", dispaSET_unleash_folder_name)\n",
    "print(\"dispaSET_unleash_folder_path:\", dispaSET_unleash_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a2c1d-bcf4-490d-8b23-e6f9e489f8cb",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 18px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    3. Usefull Variable Definition\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Entering a value to all the variables which content are going to be used in some of the next stages of this script. \n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Indicate the year of all data is referring to in the variable data_year.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d2c5023-6f7b-4683-8011-6d6d8ae1f874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntc_folder_path: /home/ray/Dispa-SET_Unleash/RawData/NTC/\n",
      "ntc_raw_data_folder_path: /home/ray/Dispa-SET_Unleash/RawData/NTC/Raw_Data_Sources/\n"
     ]
    }
   ],
   "source": [
    "# Additional string to be appended\n",
    "additional_path = \"/RawData/NTC/\"\n",
    "additional_path_1 = \"/RawData/NTC/Raw_Data_Sources/\"\n",
    "\n",
    "# Construct the Outage_Factors_folder_path variable\n",
    "ntc_folder_path = dispaSET_unleash_folder_path + additional_path\n",
    "\n",
    "# Construct the Outage_Factors_Raw_Data_folder_path variable\n",
    "ntc_raw_data_folder_path = dispaSET_unleash_folder_path + additional_path_1\n",
    "\n",
    "print(\"ntc_folder_path:\", ntc_folder_path)\n",
    "print(\"ntc_raw_data_folder_path:\", ntc_raw_data_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "286f700e-7ab3-4998-977c-19c885ff0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year to which data refers to:\n",
    "data_year = 2023\n",
    "data_year_str = str(data_year)\n",
    "\n",
    "# Define a list of country codes\n",
    "ntc_per_unit_country_list = [\"AT\", \"BE\", \"BG\", \"CH\", \"CY\", \"CZ\", \"DE\", \"DK\", \"EE\", \"GR\", \"ES\", \"FI\", \"FR\", \"HR\", \"HU\", \n",
    "                             \"IE\", \"IT\", \"LT\", \"LU\", \"LV\", \"MT\", \"NL\", \"NO\", \"PL\", \"PT\", \"RO\", \"SE\", \"SI\", \"SK\", \"UK\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbaac61-d76b-4084-9b11-78f037b92026",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 17px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    3.1. Back Up Directory\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    Saving the original files into a Back up folder.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Since in the next steps of the processing data new subfolders and files are going to be created, the original ones are saved in a back up foldet to return them as its default content ones the process will be finished.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ead4f78-bd66-49a0-91ac-08ce6afb1567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backup_folder_path: /home/ray/Dispa-SET_Unleash/RawData/NTC_backup/\n",
      "Backup created at /home/ray/Dispa-SET_Unleash/RawData/NTC_backup/\n"
     ]
    }
   ],
   "source": [
    "additional_path_5 = '/RawData/NTC_backup/'\n",
    "\n",
    "# Construct the backup_folder_path variable\n",
    "backup_folder_path = dispaSET_unleash_folder_path + additional_path_5\n",
    "\n",
    "print(\"backup_folder_path:\", backup_folder_path)\n",
    "\n",
    "# Create a backup of the directory\n",
    "if os.path.exists(backup_folder_path):\n",
    "    shutil.rmtree(backup_folder_path)  # Remove any existing backup if necessary\n",
    "shutil.copytree(ntc_folder_path, backup_folder_path)\n",
    "\n",
    "print(f\"Backup created at {backup_folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ccd47e-e246-4551-9c4f-c1b42c333a74",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 18px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    4. Reference File Definition\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Creating a file where needed information to process the raw data is used in the next stages. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ce64cf-d446-49d3-bdd2-8d82d17bb5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/country_list.csv'\n"
     ]
    }
   ],
   "source": [
    "# Define the directory and file path\n",
    "file_name = 'country_list.csv'\n",
    "file_path = os.path.join(ntc_folder_path, file_name)\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(ntc_folder_path, exist_ok=True)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(ntc_per_unit_country_list, columns=['Country_From'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"DataFrame saved to '{file_path}'\")\n",
    "ntc_country_list_file = file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf37f0c-6df4-4d79-9243-4ed45705bbee",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right; margin-left: 3.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    Tracking Variables. \n",
    "    <br>\n",
    "    <div style=\"text-align: right; margin-left: 1.50em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman;\">\n",
    "    This cells are just to confirm all the file names, file paths and other information related to the data being processed.\n",
    "    <br>\n",
    "  Also are used to ensure the inputs for next cells in order to avoid to re-enter the same information each time.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd0320a-6216-4b0f-8755-abd86f7d2d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispaSET_unleash_folder_name:                              Dispa-SET_Unleash\n",
      "dispaSET_unleash_folder_path:                              /home/ray/Dispa-SET_Unleash\n",
      "data_year:                                                 2023\n",
      "ntc_folder_path:                                           /home/ray/Dispa-SET_Unleash/RawData/NTC/\n",
      "ntc_raw_data_folder_path:                                  /home/ray/Dispa-SET_Unleash/RawData/NTC/Raw_Data_Sources/\n",
      "ntc_country_list_file:                                     /home/ray/Dispa-SET_Unleash/RawData/NTC/country_list.csv\n"
     ]
    }
   ],
   "source": [
    "print (f\"dispaSET_unleash_folder_name:                              {dispaSET_unleash_folder_name}\")\n",
    "print (f\"dispaSET_unleash_folder_path:                              {dispaSET_unleash_folder_path}\")\n",
    "print (f\"data_year:                                                 {data_year}\")\n",
    "print (f\"ntc_folder_path:                                           {ntc_folder_path}\")   \n",
    "print (f\"ntc_raw_data_folder_path:                                  {ntc_raw_data_folder_path}\")\n",
    "print (f\"ntc_country_list_file:                                     {ntc_country_list_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc969fa8-d069-4977-ae67-151a5cfad7df",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Extracting the raw data sources and upgrading its path to the ntc_country_list_file\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dd6e854-7f74-4d66-aad1-a87e74d876af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied /home/ray/Dispa-SET_Unleash/RawData/NTC/Raw_Data_Sources/2023 to /home/ray/Dispa-SET_Unleash/RawData/NTC/2023\n",
      "Processed folder path for country: AT\n",
      "Processed folder path for country: BE\n",
      "Processed folder path for country: BG\n",
      "Processed folder path for country: CH\n",
      "Processed folder path for country: CY\n",
      "Processed folder path for country: CZ\n",
      "Processed folder path for country: DE\n",
      "Processed folder path for country: DK\n",
      "Processed folder path for country: EE\n",
      "Processed folder path for country: GR\n",
      "Processed folder path for country: ES\n",
      "Processed folder path for country: FI\n",
      "Processed folder path for country: FR\n",
      "Processed folder path for country: HR\n",
      "Processed folder path for country: HU\n",
      "Processed folder path for country: IE\n",
      "Processed folder path for country: IT\n",
      "Processed folder path for country: LT\n",
      "Processed folder path for country: LU\n",
      "Processed folder path for country: LV\n",
      "Processed folder path for country: MT\n",
      "Processed folder path for country: NL\n",
      "Processed folder path for country: NO\n",
      "Processed folder path for country: PL\n",
      "Processed folder path for country: PT\n",
      "Processed folder path for country: RO\n",
      "Processed folder path for country: SE\n",
      "Processed folder path for country: SI\n",
      "Processed folder path for country: SK\n",
      "Processed folder path for country: UK\n",
      "Updated /home/ray/Dispa-SET_Unleash/RawData/NTC/country_list.csv with the new subfolder paths.\n",
      "Operation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Copy the folder and its contents\n",
    "source_folder = os.path.join(ntc_raw_data_folder_path, data_year_str)\n",
    "destination_folder = os.path.join(ntc_folder_path, data_year_str)\n",
    "\n",
    "if os.path.exists(source_folder):\n",
    "    shutil.copytree(source_folder, destination_folder)\n",
    "    print(f\"Copied {source_folder} to {destination_folder}\")\n",
    "else:\n",
    "    print(f\"Source folder {source_folder} does not exist.\")\n",
    "\n",
    "# Step 2: Update the CSV file with the paths to the subfolders\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(ntc_country_list_file)\n",
    "\n",
    "# Initialize the new column in the DataFrame\n",
    "df['Country_Folder'] = ''\n",
    "\n",
    "# Iterate over each country in ntc_per_unit_country_list and update the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    country = row['Country_From']\n",
    "    if country in ntc_per_unit_country_list:\n",
    "        # Generate the subfolder path\n",
    "        subfolder_path = os.path.join(destination_folder, country)\n",
    "        \n",
    "        # Update the 'Country_Folder' column for the corresponding 'Country_From'\n",
    "        if os.path.exists(subfolder_path):\n",
    "            df.at[index, 'Country_Folder'] = subfolder_path\n",
    "            print(f\"Processed folder path for country: {country}\")\n",
    "        else:\n",
    "            print(f\"Folder does not exist for country: {country}\")\n",
    "    else:\n",
    "        print(f\"Country {country} is not in the predefined list.\")\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df.to_csv(ntc_country_list_file, index=False)\n",
    "print(f\"Updated {ntc_country_list_file} with the new subfolder paths.\")\n",
    "print(\"Operation completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6e92de-c0dc-431f-b856-1da1820792f7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Identifying the country neighbors and writing them to the ntc_country_list_file\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4098357b-5183-420e-94a0-acb42c76d33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed subfolder for country: AT\n",
      "Processed subfolder for country: BE\n",
      "Processed subfolder for country: BG\n",
      "Processed subfolder for country: CH\n",
      "Processed subfolder for country: CY\n",
      "Processed subfolder for country: CZ\n",
      "Processed subfolder for country: DE\n",
      "Processed subfolder for country: DK\n",
      "Processed subfolder for country: EE\n",
      "Processed subfolder for country: GR\n",
      "Processed subfolder for country: ES\n",
      "Processed subfolder for country: FI\n",
      "Processed subfolder for country: FR\n",
      "Processed subfolder for country: HR\n",
      "Processed subfolder for country: HU\n",
      "Processed subfolder for country: IE\n",
      "Processed subfolder for country: IT\n",
      "Processed subfolder for country: LT\n",
      "Processed subfolder for country: LU\n",
      "Processed subfolder for country: LV\n",
      "Processed subfolder for country: MT\n",
      "Processed subfolder for country: NL\n",
      "Processed subfolder for country: NO\n",
      "Processed subfolder for country: PL\n",
      "Processed subfolder for country: PT\n",
      "Processed subfolder for country: RO\n",
      "Processed subfolder for country: SE\n",
      "Processed subfolder for country: SI\n",
      "Processed subfolder for country: SK\n",
      "Processed subfolder for country: UK\n",
      "Updated /home/ray/Dispa-SET_Unleash/RawData/NTC/country_list.csv with the neighbor filenames.\n"
     ]
    }
   ],
   "source": [
    "# Base path where the data_year_str folder is located\n",
    "base_folder_path = os.path.join(os.path.dirname(ntc_country_list_file), data_year_str)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(ntc_country_list_file)\n",
    "\n",
    "# Initialize columns for neighbors\n",
    "max_neighbors = 0\n",
    "\n",
    "# Iterate over each country in the ntc_per_unit_country_list\n",
    "for country in ntc_per_unit_country_list:\n",
    "    # Path to the subfolder for this country\n",
    "    subfolder_path = os.path.join(base_folder_path, country)\n",
    "    \n",
    "    # Check if the subfolder exists\n",
    "    if os.path.exists(subfolder_path):\n",
    "        # Get the list of files in the subfolder, removing the '.csv' extension\n",
    "        files = [os.path.splitext(f)[0] for f in os.listdir(subfolder_path) if f.endswith('.csv')]\n",
    "        \n",
    "        # Sort the files to ensure the correct order\n",
    "        files.sort()\n",
    "        \n",
    "        # Determine the maximum number of neighbors (for column creation)\n",
    "        if len(files) > max_neighbors:\n",
    "            max_neighbors = len(files)\n",
    "        \n",
    "        # Add the filenames as Neighbor_1, Neighbor_2, etc. in the DataFrame\n",
    "        for i, file_name in enumerate(files):\n",
    "            neighbor_column = f'Neighbor_{i+1}'\n",
    "            if neighbor_column not in df.columns:\n",
    "                df[neighbor_column] = ''\n",
    "            df.loc[df['Country_From'] == country, neighbor_column] = file_name\n",
    "        \n",
    "        print(f\"Processed subfolder for country: {country}\")\n",
    "    else:\n",
    "        print(f\"Subfolder does not exist for country: {country}\")\n",
    "\n",
    "# Handle the case where some countries might have fewer neighbors\n",
    "for i in range(max_neighbors):\n",
    "    neighbor_column = f'Neighbor_{i+1}'\n",
    "    if neighbor_column not in df.columns:\n",
    "        df[neighbor_column] = ''\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df.to_csv(ntc_country_list_file, index=False)\n",
    "print(f\"Updated {ntc_country_list_file} with the neighbor filenames.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4034fc-975f-433e-bdad-af5c406b3788",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Updating the Acronym of the country Greece in the ntc_country_list_file\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64f2f103-f998-46c9-9d78-03dac047bb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacements made and file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/country_list.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1411548/2584139094.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.replace('GR', 'EL') if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(ntc_country_list_file)\n",
    "\n",
    "# Replace 'GR' with 'EL' in the entire DataFrame\n",
    "df = df.applymap(lambda x: x.replace('GR', 'EL') if isinstance(x, str) else x)\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df.to_csv(ntc_country_list_file, index=False)\n",
    "\n",
    "print(f\"Replacements made and file saved: {ntc_country_list_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7099f42-94d7-4082-abb4-b5d66fe3f7c4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Updating the Acronym of the country Greece inside the ntc_folder_path\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d476864f-1677-4a2a-994c-65c01674c6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed file: /home/ray/Dispa-SET_Unleash/RawData/NTC/Raw_Data_Sources/2023/BG/GR.csv to /home/ray/Dispa-SET_Unleash/RawData/NTC/Raw_Data_Sources/2023/BG/EL.csv\n",
      "Renamed file: /home/ray/Dispa-SET_Unleash/RawData/NTC/Raw_Data_Sources/2023/IT/GR.csv to /home/ray/Dispa-SET_Unleash/RawData/NTC/Raw_Data_Sources/2023/IT/EL.csv\n",
      "Renamed directory: /home/ray/Dispa-SET_Unleash/RawData/NTC/Raw_Data_Sources/2023/GR to /home/ray/Dispa-SET_Unleash/RawData/NTC/Raw_Data_Sources/2023/EL\n",
      "Renamed file: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/BG/GR.csv to /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/BG/EL.csv\n",
      "Renamed file: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/IT/GR.csv to /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/IT/EL.csv\n",
      "Renamed directory: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/GR to /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/EL\n"
     ]
    }
   ],
   "source": [
    "# Walk through the directory tree\n",
    "for root, dirs, files in os.walk(ntc_folder_path, topdown=False):\n",
    "    # Rename files\n",
    "    for name in files:\n",
    "        if 'GR' in name:\n",
    "            new_name = name.replace('GR', 'EL')\n",
    "            old_file_path = os.path.join(root, name)\n",
    "            new_file_path = os.path.join(root, new_name)\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f\"Renamed file: {old_file_path} to {new_file_path}\")\n",
    "\n",
    "    # Rename directories\n",
    "    for name in dirs:\n",
    "        if 'GR' in name:\n",
    "            new_name = name.replace('GR', 'EL')\n",
    "            old_dir_path = os.path.join(root, name)\n",
    "            new_dir_path = os.path.join(root, new_name)\n",
    "            os.rename(old_dir_path, new_dir_path)\n",
    "            print(f\"Renamed directory: {old_dir_path} to {new_dir_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e16eee-db6e-4748-8482-a79b78729cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7019fb-9b28-4fc8-b1c7-68cb25123b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3cbf80-6979-4e87-a39c-2b6b7ce6d563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b71024b-54f4-419d-b321-3f5ea7ec49a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5492c777-af5a-4192-a526-5599e24e3def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c4e879-b40c-49c0-a43f-3bc3d055c0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e3f1981-3ba2-4536-a726-339fcb8e1485",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Joining all neighbors countries files in one file.\n",
    "<br>\n",
    "This is done for each country.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e51d4cd4-5467-4828-b84e-3e38b0ed5f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/AT/AT.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/BE/BE.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/BG/BG.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/CH/CH.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/CZ/CZ.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/DE/DE.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/DK/DK.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/EE/EE.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/EL/EL.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/ES/ES.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/FI/FI.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/FR/FR.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/HR/HR.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/HU/HU.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/IE/IE.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/IT/IT.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/LT/LT.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/LU/LU.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/LV/LV.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/MT/MT.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/NL/NL.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/NO/NO.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/PL/PL.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/PT/PT.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/RO/RO.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/SE/SE.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/SI/SI.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/SK/SK.csv'\n",
      "Joined CSV file saved to '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/UK/UK.csv'\n",
      "All data has been processed and saved.\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(ntc_country_list_file)\n",
    "\n",
    "# Ensure the column 'Country_Folder' exists\n",
    "if 'Country_Folder' not in df.columns:\n",
    "    raise ValueError(\"Column 'Country_Folder' does not exist in the CSV file\")\n",
    "\n",
    "# Function to join CSV files in a directory\n",
    "def join_csv_files_in_directory(directory_path):\n",
    "    csv_files = [f for f in os.listdir(directory_path) if f.endswith('.csv')]\n",
    "    if not csv_files:\n",
    "        return None\n",
    "    \n",
    "    # Read all CSV files into DataFrames\n",
    "    dataframes = {csv_file: pd.read_csv(os.path.join(directory_path, csv_file)) for csv_file in csv_files}\n",
    "    \n",
    "    # Find the CSV file with the largest number of rows\n",
    "    largest_file = max(dataframes, key=lambda x: len(dataframes[x]))\n",
    "    base_df = dataframes[largest_file].iloc[:, :2].copy()\n",
    "    base_df.columns = [base_df.columns[0], largest_file.replace('.csv', '')]\n",
    "    \n",
    "    # Merge the other CSV files based on the first column\n",
    "    for csv_file, df in dataframes.items():\n",
    "        if csv_file == largest_file:\n",
    "            continue\n",
    "        temp_df = df.iloc[:, [0, 1]]\n",
    "        temp_df.columns = [temp_df.columns[0], csv_file.replace('.csv', '')]\n",
    "        base_df = pd.merge(base_df, temp_df, on=base_df.columns[0], how='left')\n",
    "    \n",
    "    return base_df\n",
    "\n",
    "# Create a new column for the paths of the new CSV files\n",
    "df['Country_File_Path'] = ''\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    country_folder = row['Country_Folder']\n",
    "    \n",
    "    # Join CSV files in the directory\n",
    "    joined_df = join_csv_files_in_directory(country_folder)\n",
    "    \n",
    "    if joined_df is not None:\n",
    "        # Define the output file path\n",
    "        output_file = os.path.join(country_folder, f\"{os.path.basename(country_folder)}.csv\")\n",
    "        \n",
    "        # Save the joined DataFrame to a new CSV file\n",
    "        joined_df.to_csv(output_file, index=False)\n",
    "        \n",
    "        # Update the DataFrame with the path of the new CSV file\n",
    "        df.at[index, 'Country_File_Path'] = output_file\n",
    "\n",
    "        print(f\"Joined CSV file saved to '{output_file}'\")\n",
    "\n",
    "# Save the updated DataFrame back to the main CSV file\n",
    "df.to_csv(ntc_country_list_file, index=False)\n",
    "\n",
    "print(\"All data has been processed and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25085cd9-7019-468e-b4b2-3d1f7074fb92",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Giving the header columns to the just joined files.\n",
    "<br>\n",
    "This headers indicates the direction of the power flow for each country.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa96075d-b062-4ef4-998e-de1c65d51a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/AT/AT.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/BE/BE.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/BG/BG.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/CH/CH.csv'\n",
      "File path 'nan' does not exist or is empty. Skipping...\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/CZ/CZ.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/DE/DE.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/DK/DK.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/EE/EE.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/EL/EL.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/ES/ES.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/FI/FI.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/FR/FR.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/HR/HR.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/HU/HU.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/IE/IE.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/IT/IT.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/LT/LT.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/LU/LU.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/LV/LV.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/MT/MT.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/NL/NL.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/NO/NO.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/PL/PL.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/PT/PT.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/RO/RO.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/SE/SE.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/SI/SI.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/SK/SK.csv'\n",
      "Updated headers in '/home/ray/Dispa-SET_Unleash/RawData/NTC/2023/UK/UK.csv'\n",
      "All CSV files have been processed.\n"
     ]
    }
   ],
   "source": [
    "# Read the main CSV file into a DataFrame\n",
    "df = pd.read_csv(ntc_country_list_file)\n",
    "\n",
    "# Ensure the required columns exist\n",
    "if 'Country_From' not in df.columns or 'Country_File_Path' not in df.columns:\n",
    "    raise ValueError(\"The CSV file must contain 'Country_From' and 'Country_File_Path' columns.\")\n",
    "\n",
    "# Function to update the headers of a CSV file\n",
    "def update_csv_headers(file_path, new_header_prefix):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    csv_df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Get the current headers\n",
    "    current_headers = csv_df.columns.tolist()\n",
    "    \n",
    "    # Create new headers for columns from the second column onward\n",
    "    new_headers = [current_headers[0]] + [f\"{new_header_prefix} -> {col}\" for col in current_headers[1:]]\n",
    "    \n",
    "    # Update the DataFrame with the new headers\n",
    "    csv_df.columns = new_headers\n",
    "    \n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    csv_df.to_csv(file_path, index=False)\n",
    "    print(f\"Updated headers in '{file_path}'\")\n",
    "\n",
    "# Iterate through each row in the main DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    country_from = row['Country_From']\n",
    "    country_file_path = row['Country_File_Path']\n",
    "    \n",
    "    # Check if the file path is not empty and exists\n",
    "    if pd.notna(country_file_path) and os.path.exists(country_file_path):\n",
    "        update_csv_headers(country_file_path, country_from)\n",
    "    else:\n",
    "        print(f\"File path '{country_file_path}' does not exist or is empty. Skipping...\")\n",
    "\n",
    "print(\"All CSV files have been processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721465cf-8d99-4322-8c96-4f36ab6d3abd",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 18px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    5. Raw Data Format\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Addapting the time step data to the UTC for all the countries.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24f75d87-0e46-4062-a33c-c034bbc2657a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/AT/AT.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/BE/BE.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/BG/BG.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/CH/CH.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/CZ/CZ.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/DE/DE.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/DK/DK.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/EE/EE.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/EL/EL.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/ES/ES.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/FI/FI.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/FR/FR.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/HR/HR.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/HU/HU.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/IE/IE.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/IT/IT.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/LT/LT.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/LU/LU.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/LV/LV.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/MT/MT.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/NL/NL.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/NO/NO.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/PL/PL.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/PT/PT.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/RO/RO.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/SE/SE.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/SI/SI.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/SK/SK.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/UK/UK.csv\n"
     ]
    }
   ],
   "source": [
    "# Read the country list CSV file\n",
    "country_list_df = pd.read_csv(ntc_country_list_file)\n",
    "\n",
    "# Ensure the 'Country_File_Path' column exists\n",
    "if 'Country_File_Path' not in country_list_df.columns:\n",
    "    raise ValueError(\"Column 'Country_File_Path' does not exist in the CSV file\")\n",
    "\n",
    "# Define the function to convert time to UTC\n",
    "def convert_to_utc(time_str):\n",
    "    local_time = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S%z')\n",
    "    utc_time = local_time.astimezone(pytz.utc)\n",
    "    return utc_time.strftime('%Y-%m-%d %H:%M:%S%z')\n",
    "\n",
    "# Process each CSV file\n",
    "for file_path in country_list_df['Country_File_Path'].dropna():\n",
    "    # Ensure the file exists\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if the 'index' column exists\n",
    "    if 'index' not in df.columns:\n",
    "        print(f\"'index' column not found in file: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    # Convert the 'index' column to UTC\n",
    "    df['index'] = df['index'].apply(convert_to_utc)\n",
    "    \n",
    "    # Save the updated CSV file\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Updated file saved: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22b47cee-8480-4512-85bc-99361edfffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/AT/AT.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/BE/BE.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/BG/BG.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/CH/CH.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/CZ/CZ.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/DE/DE.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/DK/DK.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/EE/EE.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/EL/EL.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/ES/ES.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/FI/FI.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/FR/FR.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/HR/HR.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/HU/HU.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/IE/IE.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/IT/IT.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/LT/LT.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/LU/LU.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/LV/LV.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/MT/MT.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/NL/NL.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/NO/NO.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/PL/PL.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/PT/PT.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/RO/RO.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/SE/SE.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/SI/SI.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/SK/SK.csv\n",
      "Updated file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023/UK/UK.csv\n"
     ]
    }
   ],
   "source": [
    "# Read the country list CSV file\n",
    "country_list_df = pd.read_csv(ntc_country_list_file)\n",
    "\n",
    "# Ensure the 'Country_File_Path' column exists\n",
    "if 'Country_File_Path' not in country_list_df.columns:\n",
    "    raise ValueError(\"Column 'Country_File_Path' does not exist in the CSV file\")\n",
    "\n",
    "# Function to update the year in the 'index' column\n",
    "def update_index_year(df, data_year):\n",
    "    # Ensure the 'index' column exists\n",
    "    if 'index' not in df.columns:\n",
    "        raise ValueError(\"'index' column not found in DataFrame\")\n",
    "    \n",
    "    # Update the year in the 'index' column\n",
    "    df['index'] = df['index'].apply(lambda x: f\"{data_year}{x[4:]}\" if str(x)[:4] != str(data_year) else x)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Process each CSV file specified in the 'Country_File_Path' column\n",
    "for file_path in country_list_df['Country_File_Path'].dropna():\n",
    "    # Ensure the file exists\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Ensure there are enough rows to move the first four rows to the last\n",
    "    if len(df) < 4:\n",
    "        print(f\"Not enough rows to process in file: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Extract the first four rows (excluding headers)\n",
    "    first_four_rows = df.iloc[:4].copy()\n",
    "    \n",
    "    # Drop the first four rows from the DataFrame\n",
    "    df = df.iloc[4:].reset_index(drop=True)\n",
    "    \n",
    "    # Append the first_four_rows to the end of the DataFrame\n",
    "    df = pd.concat([df, first_four_rows]).reset_index(drop=True)\n",
    "    \n",
    "    # Update the 'index' column year\n",
    "    df = update_index_year(df, data_year)\n",
    "    \n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Updated file saved: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda5d61-6dfc-4a9f-9deb-43c410226b5d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 18px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    6. Net Transfer Capacities Clean File\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Joining all the net transfer capacity data to a single csv file with named as the analized year.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4eb05a5-9b11-4088-af0a-04c0a0cd97da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV file saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/2023.csv\n"
     ]
    }
   ],
   "source": [
    "# Read the country list CSV file\n",
    "country_list_df = pd.read_csv(ntc_country_list_file)\n",
    "\n",
    "# Ensure the 'Country_File_Path' column exists\n",
    "if 'Country_File_Path' not in country_list_df.columns:\n",
    "    raise ValueError(\"Column 'Country_File_Path' does not exist in the CSV file\")\n",
    "\n",
    "# Process each CSV file specified in the 'Country_File_Path' column\n",
    "file_paths = country_list_df['Country_File_Path'].dropna().tolist()\n",
    "\n",
    "# Identify the CSV file with the largest number of rows\n",
    "max_rows = 0\n",
    "base_df = None\n",
    "for file_path in file_paths:\n",
    "    # Ensure the file exists\n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        if len(df) > max_rows:\n",
    "            max_rows = len(df)\n",
    "            base_df = df.copy()\n",
    "\n",
    "# If no base_df was found, raise an error\n",
    "if base_df is None:\n",
    "    raise ValueError(\"No valid CSV files found.\")\n",
    "\n",
    "# Initialize the combined DataFrame with the first column from the base DataFrame\n",
    "combined_df = pd.DataFrame(base_df.iloc[:, 0])\n",
    "combined_df.columns = [base_df.columns[0]]  # Keep the original name of the first column\n",
    "\n",
    "# Add data from each CSV file to the combined DataFrame\n",
    "for file_path in file_paths:\n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Merge the data based on the first column\n",
    "        combined_df = pd.merge(combined_df, df, on=base_df.columns[0], how='left')\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file named after the data_year variable\n",
    "output_file_path = os.path.join(ntc_folder_path, f\"{data_year}.csv\")\n",
    "combined_df.to_csv(output_file_path, index=False)\n",
    "print(f\"Combined CSV file saved: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305cd6f0-b8c2-4f3a-988f-8fcd56fe90bd",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color: skyblue\">\n",
    "Dividing the clean data in time stepts of 15 minutes, 30 minutes, and 1 hour.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61676596-c747-4700-804d-4b8cf7e0d61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1411548/4274416861.py:17: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  resampled_df = df.set_index('index').resample(interval).first().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/1h/2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1411548/4274416861.py:17: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  resampled_df = df.set_index('index').resample(interval).first().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/30min/2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1411548/4274416861.py:17: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  resampled_df = df.set_index('index').resample(interval).first().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved: /home/ray/Dispa-SET_Unleash/RawData/NTC/15min/2023.csv\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = os.path.join(ntc_folder_path, f'{data_year}.csv')\n",
    "\n",
    "# Create the new directories\n",
    "intervals = ['1h', '30min', '15min']\n",
    "for interval in intervals:\n",
    "    os.makedirs(os.path.join(ntc_folder_path, interval), exist_ok=True)\n",
    "\n",
    "# Read the original CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Convert the 'index' column to datetime\n",
    "df['index'] = pd.to_datetime(df['index'], format='%Y-%m-%d %H:%M:%S%z')\n",
    "\n",
    "# Function to extract rows at a specific time step and save to a new CSV file\n",
    "def extract_and_save(df, interval, folder_name):\n",
    "    # Resample the DataFrame\n",
    "    resampled_df = df.set_index('index').resample(interval).first().reset_index()\n",
    "    \n",
    "    # Define the new file path\n",
    "    new_file_path = os.path.join(ntc_folder_path, folder_name, f'{data_year}.csv')\n",
    "    \n",
    "    # Save the resampled DataFrame to the new CSV file\n",
    "    resampled_df.to_csv(new_file_path, index=False)\n",
    "    print(f\"File saved: {new_file_path}\")\n",
    "\n",
    "# Extract and save rows at different time steps\n",
    "extract_and_save(df, '1H', '1h')\n",
    "extract_and_save(df, '30T', '30min')\n",
    "extract_and_save(df, '15T', '15min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff1dc11-48c0-4bf3-80bf-aaaa517f0a15",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color: skyblue\">\n",
    "Correcting those non numeric or empty fields from the processed data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b158ceb-4997-4dfa-af03-8af49b745a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and updated /home/ray/Dispa-SET_Unleash/RawData/NTC/1h/2023.csv\n",
      "Processed and updated /home/ray/Dispa-SET_Unleash/RawData/NTC/15min/2023.csv\n",
      "Processed and updated /home/ray/Dispa-SET_Unleash/RawData/NTC/30min/2023.csv\n"
     ]
    }
   ],
   "source": [
    "# List of subfolders to check\n",
    "subfolders = ['1h', '15min', '30min']\n",
    "\n",
    "# Iterate through each subfolder\n",
    "for subfolder in subfolders:\n",
    "    # Construct the full path to the CSV file\n",
    "    csv_file_path = os.path.join(ntc_folder_path, subfolder, f'{data_year}.csv')\n",
    "    \n",
    "    # Check if the CSV file exists\n",
    "    if os.path.exists(csv_file_path):\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        \n",
    "        # Process the relevant columns (from the second column onwards)\n",
    "        for col in df.columns[1:]:\n",
    "            # Replace non-numeric values with '0'\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "        \n",
    "        # Save the modified DataFrame back to the CSV file\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "        \n",
    "        print(f\"Processed and updated {csv_file_path}\")\n",
    "    else:\n",
    "        print(f\"CSV file {csv_file_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed8da8-803c-4491-a7a4-f146957df9d1",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Copying the time already formated Net Transfer Capacities data to the main Dispa-SET data base dirtectory\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a6d3920-309e-497a-bee8-f7d39979e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_path_2 = \"/Database/NTC/\"\n",
    "\n",
    "# Construct the power_plants_raw_data_folder_path variable\n",
    "ntc_data_base_folder_path = dispaSET_unleash_folder_path + additional_path_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f16a0c31-7f06-4136-beb2-ecbad059b836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied /home/ray/Dispa-SET_Unleash/RawData/NTC/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/NTC/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/NTC/30min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/NTC/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/NTC/15min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/NTC/15min/2023.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the subfolder names\n",
    "subfolders = ['1h', '30min', '15min']\n",
    "\n",
    "# Function to copy files\n",
    "def copy_files(data_year, source_base_path, dest_base_path, subfolders):\n",
    "    for subfolder in subfolders:\n",
    "        source_path = os.path.join(source_base_path, subfolder, f\"{data_year}.csv\")\n",
    "        dest_folder_path = os.path.join(dest_base_path, subfolder)\n",
    "\n",
    "        # Create the destination subfolder if it does not exist\n",
    "        os.makedirs(dest_folder_path, exist_ok=True)\n",
    "\n",
    "        dest_path = os.path.join(dest_folder_path, f\"{data_year}.csv\")\n",
    "        \n",
    "        # Copy the file\n",
    "        if os.path.isfile(source_path):\n",
    "            shutil.copy2(source_path, dest_path)\n",
    "            print(f\"Copied {source_path} to {dest_path}\")\n",
    "        else:\n",
    "            print(f\"File {source_path} does not exist\")\n",
    "\n",
    "# Call the function\n",
    "copy_files(data_year, ntc_folder_path, ntc_data_base_folder_path, subfolders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa7dd5f-f388-47fb-9186-d89f711aa0d1",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 17px; font-family: TimesNewRoman; color:skyblue\">\n",
    "7. Net Transfer Capacity Folder Back Up\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Once all the formating process was done the Net Transfer Capacity Folder is restored to its defoult state.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc101255-0315-4d52-928f-28b59d032603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory restored to original state from /home/ray/Dispa-SET_Unleash/RawData/NTC_backup/\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(ntc_folder_path):\n",
    "    shutil.rmtree(ntc_folder_path)  # Remove the current directory\n",
    "shutil.copytree(backup_folder_path, ntc_folder_path)\n",
    "\n",
    "print(f\"Directory restored to original state from {backup_folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc87ba35-c1a3-4b1d-9478-f493ebc8fdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup folder /home/ray/Dispa-SET_Unleash/RawData/NTC_backup/ deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(backup_folder_path)\n",
    "print(f\"Backup folder {backup_folder_path} deleted successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
