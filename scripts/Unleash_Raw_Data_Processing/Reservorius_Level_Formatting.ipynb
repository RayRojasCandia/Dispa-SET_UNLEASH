{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee4d37af-ffee-48a4-9e9b-e4c9ff2ab699",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; margin-left: 0em; font-weight: bold; font-size: 20px; font-family: TimesNewRoman; color: skyblue\">\n",
    "    TIME SERIES DATA PROCESSING\n",
    "    <br>\n",
    "    RESERVOIRS LEVEL\n",
    "<div style=\"text-align: center; margin-left: 0em; font-weight: bold; font-size: 18px; font-family: TimesNewRoman; color: skyblue\">\n",
    "    Main Formatting Notebook\n",
    "</div>\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color: skyblue\">\n",
    "Each part of the following script was used to proccess the raw data for the Reservoirs Level Time Series Raw Data for all the european countries of the Dispa-SET_Unleash project.\n",
    "<br>\n",
    "Read explanation text cells to follow and understand all the process until final results were got stept by step.\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 18px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    1. Notebook Set Up\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    Importing needed libraries\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0be3a50f-fd12-448d-8853-30b62c1c29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import http.client\n",
    "from multiprocessing import Pool\n",
    "import shutil\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9748f975-71e8-4f2f-8eeb-59542e5da6b4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 18px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    2. Dispa-SET_Unleash Folder Path\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    Determinning dynamically the zone_folder_path based on the location of the \"Dispa-SET_Unleash\" folder relative to the current working directory.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "If the \"Dispa-SET_Unleash\" folder is copied to a different machine or location, the dispaSET_unleash_folder_path variable will automatically adjust accordingly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0adc2ac-010f-48e9-a2f4-4ba016539343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispaSET_unleash_folder_name: Dispa-SET_Unleash\n",
      "dispaSET_unleash_folder_path: /home/ray/Dispa-SET_Unleash\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Navigate to the parent directory of \"Dispa-SET_Unleash\"\n",
    "dispaSET_unleash_parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "# Get the path to the \"Dispa-SET_Unleash\" folder\n",
    "dispaSET_unleash_folder_path = os.path.dirname(dispaSET_unleash_parent_directory)\n",
    "\n",
    "# Construct the dispaSET_unleash_folder_name variable\n",
    "dispaSET_unleash_folder_name = os.path.basename(dispaSET_unleash_folder_path)\n",
    "\n",
    "print(\"dispaSET_unleash_folder_name:\", dispaSET_unleash_folder_name)\n",
    "print(\"dispaSET_unleash_folder_path:\", dispaSET_unleash_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876bb980-d4b6-4773-8679-f63ae633ff22",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 18px; font-family: TimesNewRoman; color:skyblue\">\n",
    "3. Usefull Variable Definition\n",
    "</div>\n",
    "<div style=\"text-align: left; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Entering a value to all the variables which content are going to be used in some of the next stages of this script. \n",
    "</div>\n",
    "<div style=\"text-align: left; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Indicate the year of all data is referring to in the variable data_year.\n",
    "<br>\n",
    "The universal_standar_time variable is going to be used to download all the time series data in this horary zone. Additionally as each european country belongs a particular time sector the corresponding time series data related to its time sector are going to be downloaded as well but in a different file.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "972f8c34-34a6-49bf-846b-663a701b8b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year to which data refers to:\n",
    "data_year = 2023\n",
    "\n",
    "# Define lists of countries and standard times\n",
    "countries = [\n",
    "    \"Austria\", \"Belgium\", \"Bulgaria\", \"Switzerland\", \"Cyprus\", \"Czech Republic\",\n",
    "    \"Germany\", \"Denmark\", \"Estonia\", \"Greece\", \"Spain\", \"Finland\", \"France\",\n",
    "    \"Croatia\", \"Hungary\", \"Ireland\", \"Italy\", \"Lithuania\", \"Luxembourg\", \"Latvia\",\n",
    "    \"Malta\", \"Netherlands\", \"Norway\", \"Poland\", \"Portugal\", \"Romania\", \"Sweden\",\n",
    "    \"Slovenia\", \"Slovakia\", \"United Kingdom\"\n",
    "]\n",
    "\n",
    "dispaSET_codes = [\"AT\", \"BE\", \"BG\", \"CH\", \"CY\", \"CZ\", \"DE\", \"DK\", \"EE\", \"EL\", \"ES\", \"FI\", \"FR\", \"HR\", \"HU\", \n",
    "                  \"IE\", \"IT\", \"LT\", \"LU\", \"LV\", \"MT\", \"NL\", \"NO\", \"PL\", \"PT\", \"RO\", \"SE\", \"SI\", \"SK\", \"UK\"\n",
    "]\n",
    "\n",
    "# Universal standad time:\n",
    "standard_time = 'UTC'\n",
    "\n",
    "# Western European Time:\n",
    "#standard_time = 'WET_WEST'\n",
    "\n",
    "# Central European Time:\n",
    "#standard_time = 'CET_CEST'\n",
    "\n",
    "# Eastern European Time:\n",
    "#standard_time = 'EET_EST'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eea56d3-c992-491c-b8e1-40f4f681c932",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 18px; font-family: TimesNewRoman; color:skyblue\">\n",
    "4. Reservoirs Level Directories Definition\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Creating the folders that are going to content all the data realted to the Reservoirs Level time series.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Futher the downloaded raw data is going to be used to get the Reservoirs Level time series. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9f94ca-9e6b-42e0-b0b4-92b68ee917c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference_data_folder_path: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/\n",
      "reservoir_level_folder_path: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/\n",
      "scaled_inflows_folder_path: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/\n",
      "reservoir_level_raw_data_folder_path: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/\n"
     ]
    }
   ],
   "source": [
    "# Additional string to be appended\n",
    "additional_path = \"/RawData/HydroData/ReservoirLevel/\"\n",
    "additional_path_1 = \"/RawData/HydroData/ScaledInflows/\"\n",
    "additional_path_2 = \"/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/\"\n",
    "\n",
    "# Construct the standard_time_data_folder_path variable\n",
    "reference_data_folder_path = dispaSET_unleash_folder_path + additional_path\n",
    "\n",
    "# Construct the Reservoir_Level_folder_path variable\n",
    "reservoir_level_folder_path = dispaSET_unleash_folder_path + additional_path\n",
    "\n",
    "# Construct the Scalled_Inflow_folder_path variable\n",
    "scaled_inflows_folder_path = dispaSET_unleash_folder_path + additional_path_1\n",
    "\n",
    "# Construct the Reservoir_Level_raw_rada_folder_path variable\n",
    "reservoir_level_raw_data_folder_path = dispaSET_unleash_folder_path + additional_path_2\n",
    "\n",
    "print(\"reference_data_folder_path:\", reference_data_folder_path)\n",
    "print(\"reservoir_level_folder_path:\", reservoir_level_folder_path)\n",
    "print(\"scaled_inflows_folder_path:\", scaled_inflows_folder_path)\n",
    "print(\"reservoir_level_raw_data_folder_path:\", reservoir_level_raw_data_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c0a365-3606-4025-9d2b-ce2c3beeba5c",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 17px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    4.1. Back Up Directory\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    Saving the original files into a Back up folder.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Since in the next steps of the processing data new subfolders and files are going to be created, the original ones are saved in a back up foldet to return them as its default content ones the process will be finished.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe1d977-b7bb-4ca6-b5b0-4996aa2a392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backup_folder_path: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel_backup/\n",
      "Backup created at /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel_backup/\n"
     ]
    }
   ],
   "source": [
    "additional_path_5 = '/RawData/HydroData/ReservoirLevel_backup/'\n",
    "\n",
    "# Construct the backup_folder_path variable\n",
    "backup_folder_path = dispaSET_unleash_folder_path + additional_path_5\n",
    "\n",
    "print(\"backup_folder_path:\", backup_folder_path)\n",
    "\n",
    "# Create a backup of the directory\n",
    "if os.path.exists(backup_folder_path):\n",
    "    shutil.rmtree(backup_folder_path)  # Remove any existing backup if necessary\n",
    "shutil.copytree(reservoir_level_folder_path, backup_folder_path)\n",
    "\n",
    "print(f\"Backup created at {backup_folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cb7fed-33dd-4823-aec1-1026a88d608d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 18px; font-family: TimesNewRoman; color:skyblue\">\n",
    "5. Reference File\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Creating a file where auxiliar data needed to the fortmatting process is going to be written such as file is named:\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Reference_Data.csv\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab7b5ae5-c21c-4a9f-8de3-7d0ab6fb7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame({'Country': countries, 'Dispa-SET_Code': dispaSET_codes, 'Standar_Time': standard_time, 'Data_Year': data_year})\n",
    "\n",
    "\n",
    "reference_data_file_name = 'Reference_Data.csv'\n",
    "\n",
    "# Construct the full file path\n",
    "reference_data_file_path = os.path.join(reference_data_folder_path, reference_data_file_name)\n",
    "\n",
    "# Create the CSV file with the specified name\n",
    "with open(reference_data_file_path, 'w') as f:\n",
    "    # Optional: Write a header if needed\n",
    "    # f.write(\"header1,header2,header3\\n\")\n",
    "\n",
    "# Save DataFrame to the CSV file\n",
    "    df.to_csv(reference_data_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850810b4-b948-408e-a2ee-5b23e48ff37e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 17px; font-family: TimesNewRoman; color:skyblue\">\n",
    "5.1. Folder Data Creation\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Creating the folder by country that is going to storage the processed reservoiur time series.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77cf791c-51d2-444a-87b0-0dfbdaf5679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/2023_1.csv\n",
      "CSV file created: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/2023_1.csv\n"
     ]
    }
   ],
   "source": [
    "# Read the reference data file\n",
    "df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Create a new column 'Zone_Folder_Path' and 'Single_Raw_Data_File_Path'\n",
    "df['Zone_Folder_Path'] = reference_data_folder_path + df['Dispa-SET_Code'].astype(str)\n",
    "df['Single_Raw_Data_File_Path'] = \"\"  # Initialize the new column with empty strings\n",
    "\n",
    "# Iterate over each row and create a CSV file\n",
    "for index, row in df.iterrows():\n",
    "    zone_folder_path = row['Zone_Folder_Path']\n",
    "    output_csv_file_path = os.path.join(zone_folder_path, f\"{data_year}_1.csv\")\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(os.path.dirname(output_csv_file_path), exist_ok=True)\n",
    "    \n",
    "    # Write the CSV file\n",
    "    with open(output_csv_file_path, 'w') as f:\n",
    "        # Write header if needed\n",
    "        f.write(\"Header1,\")\n",
    "        \n",
    "        # Write data (if needed)\n",
    "        # f.write(\"Data1,Data2,...\\n\")\n",
    "        \n",
    "        # Here, you can write any data you want into the CSV file\n",
    "    \n",
    "    # Print the message for file creation\n",
    "    print(f\"CSV file created: {output_csv_file_path}\")\n",
    "    \n",
    "    # Update the 'Single_Raw_Data_File_Path' column with the path of the created CSV file\n",
    "    df.at[index, 'Single_Raw_Data_File_Path'] = output_csv_file_path\n",
    "\n",
    "# Save the updated DataFrame back to the reference data CSV file\n",
    "df.to_csv(reference_data_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715427b6-b936-49b8-b1a1-6aeb54cb657e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right; margin-left: 3.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    Tracking Variables. \n",
    "    <br>\n",
    "    <div style=\"text-align: right; margin-left: 1.50em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    This cells are just to confirm all the file names, file paths and other information related to the data being processed.\n",
    "    <br>\n",
    "  Also are used to ensure the inputs for next cells in order to avoid to re-enter the same information each time.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d5b5266-85bc-4bd7-901f-7945b88cf1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispaSET_unleash_folder_name:                              Dispa-SET_Unleash\n",
      "dispaSET_unleash_folder_path:                              /home/ray/Dispa-SET_Unleash\n",
      "data_year:                                                 2023\n",
      "reference_data_folder_path:                                /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/\n",
      "reference_data_file_name:                                  Reference_Data.csv\n",
      "reference_data_file_path:                                  /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Reference_Data.csv\n",
      "reservoir_level_folder_path:                               /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/\n",
      "reservoir_level_raw_data_folder_path:                      /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/\n",
      "standard_time:                                             UTC\n"
     ]
    }
   ],
   "source": [
    "print (f\"dispaSET_unleash_folder_name:                              {dispaSET_unleash_folder_name}\")\n",
    "print (f\"dispaSET_unleash_folder_path:                              {dispaSET_unleash_folder_path}\")\n",
    "print (f\"data_year:                                                 {data_year}\")\n",
    "print (f\"reference_data_folder_path:                                {reference_data_folder_path}\")\n",
    "print (f\"reference_data_file_name:                                  {reference_data_file_name}\")\n",
    "print (f\"reference_data_file_path:                                  {reference_data_file_path}\")\n",
    "print (f\"reservoir_level_folder_path:                               {reservoir_level_folder_path}\")\n",
    "print (f\"reservoir_level_raw_data_folder_path:                      {reservoir_level_raw_data_folder_path}\")\n",
    "print (f\"standard_time:                                             {standard_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7c139-19f4-492d-a7cb-6970ef9b8580",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 17px; font-family: TimesNewRoman; color:skyblue\">\n",
    "6. Raw Data\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Giving the path to the reservoir level raw data files.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1ffc5c6-4a28-4849-8626-1302c66215cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/AT/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/BE/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/BG/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/CH/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/CY/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/CZ/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/DE/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/DK/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/EE/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/EL/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/ES/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/FI/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/FR/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/HR/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/HU/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/IE/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/IT/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/LT/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/LU/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/LV/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/MT/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/NL/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/NO/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/PL/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/PT/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/RO/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/SE/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/SI/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/SK/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/Raw_Data.csv\n",
      "Copied file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/UK/Raw_Data.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/Raw_Data.csv\n"
     ]
    }
   ],
   "source": [
    "def copy_and_update_csv(reference_data_file_path, reservoir_level_raw_data_folder_path, dispaSET_codes):\n",
    "    \"\"\"Copies CSV files to new folders and updates the reference data.\n",
    "\n",
    "    Args:\n",
    "        reference_data_file_path (str): Path to the reference data CSV file.\n",
    "        reservoir_level_raw_data_folder_path (str): Path to the raw data folder.\n",
    "        dispaSET_codes (list): List of country codes.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "    for country in dispaSET_codes:\n",
    "        source_folder = os.path.join(reservoir_level_raw_data_folder_path, country)\n",
    "        source_file = os.path.join(source_folder, \"Raw_Data.csv\")\n",
    "        destination_folder = os.path.join(os.path.dirname(reference_data_file_path), country)\n",
    "        destination_file = os.path.join(destination_folder, \"Raw_Data.csv\")\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(destination_file)):\n",
    "            os.makedirs(os.path.dirname(destination_file))\n",
    "\n",
    "        shutil.copy2(source_file, destination_file)\n",
    "        df.loc[df['Dispa-SET_Code'] == country, 'Raw_Data_File_Path'] = destination_file\n",
    "        print(f\"Copied file: {source_file} to {destination_file}\")\n",
    "\n",
    "    df.to_csv(reference_data_file_path, index=False)\n",
    "\n",
    "copy_and_update_csv(reference_data_file_path, reservoir_level_raw_data_folder_path, dispaSET_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49896236-ff50-4833-87ce-a1699f3f41d2",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 17px; font-family: TimesNewRoman; color:skyblue\">\n",
    "6.1. Raw Data Headers\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Adding column names.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "All the raw data were downloaded without columns identification, the corresponding header to each column is added.\n",
    "<br>\n",
    "Additionally an extra row is going to be added to the recently downloaded data for future interpolation processes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcdc9c85-a2c6-4e20-9b3d-ce88f22583bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/Raw_Data.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/Raw_Data.csv'.\n",
      "All empty rows added successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the CSV file containing the file paths\n",
    "#standard_time_data_file_path = \"/home/ray/Dispa-SET_Unleash/RawData/AvailabiltyFactors/Standard_Time_Data.csv\"\n",
    "\n",
    "# Read the CSV file containing the paths\n",
    "df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "success = True\n",
    "\n",
    "# Iterate through each file path in the column 'Time_Series_Raw_Data_File_Path'\n",
    "for index, row in df.iterrows():\n",
    "    file_path = row['Raw_Data_File_Path']\n",
    "    \n",
    "    # Open the existing CSV file in read mode\n",
    "    with open(file_path, 'r', newline='') as file:\n",
    "        # Read the existing content\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    # Insert a new empty row at the beginning\n",
    "    rows.insert(0, [])\n",
    "\n",
    "    # Write the updated content back to the CSV file\n",
    "    with open(file_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(rows)\n",
    "        \n",
    "    print(f\"Empty row added at the beginning of file '{file_path}'.\")\n",
    "\n",
    "print(\"All empty rows added successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e5f311-61af-4f82-9993-6d1ec8ed6fb4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Giving the Year Columns to the Raw Data.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "The raw data has data from various years in each columns (starting the second column).\n",
    "<br>\n",
    "It is needed to identify what year each data belongs to.\n",
    "<br>\n",
    "For this, the corresponding header is going to be given to each column.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 4.0em; font-weight: unbold; font-size: 12px; font-family: TimesNewRoman; color:skyblue\">\n",
    "The value of the start_year and end_year variables has to be the same than those used in the Reservorius Level Downloading Notebook.\n",
    "<br>\n",
    "In the current code, this values are set in 2016 and 2024 since this are the years which are been working with.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665823e5-189d-453e-8f39-f664440c0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2016\n",
    "end_year = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54411d9d-85b3-4531-bcb8-c3d7f181cfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers copied successfully to the first empty row of all files.\n"
     ]
    }
   ],
   "source": [
    "year_range = list(range(start_year+1, end_year+1))\n",
    "\n",
    "# Convert the integer values to strings\n",
    "start_year_str = str(start_year)\n",
    "year_range_str = [str(year) for year in year_range]\n",
    "\n",
    "# Create the headers list\n",
    "headers = ['Week', start_year_str] + year_range_str\n",
    "\n",
    "# Define the path to the CSV file containing the file paths\n",
    "#standard_time_data_file_path = \"/home/ray/Dispa-SET_Unleash/RawData/AvailabiltyFactors/Standard_Time_Data.csv\"\n",
    "\n",
    "# Read the CSV file containing the paths\n",
    "df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "success = True\n",
    "\n",
    "# Iterate through each file path in the column 'Time_Series_Raw_Data_File_Path'\n",
    "for index, row in df.iterrows():\n",
    "    file_path = row['Raw_Data_File_Path']\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Open the file for reading\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Find the index of the first empty row\n",
    "        empty_row_index = next((i for i, line in enumerate(lines) if line.strip() == \"\"), None)\n",
    "\n",
    "        # If an empty row is found, copy the headers to it\n",
    "        if empty_row_index is not None:\n",
    "            lines[empty_row_index] = ','.join(headers) + '\\n'\n",
    "\n",
    "            # Write the updated lines back to the file\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.writelines(lines)\n",
    "        else:\n",
    "            print(f\"No empty row found in file '{file_path}'. Headers not copied.\")\n",
    "    else:\n",
    "        success = False\n",
    "        print(f\"Error: File '{file_path}' does not exist.\")\n",
    "\n",
    "if success:\n",
    "    print(\"Headers copied successfully to the first empty row of all files.\")\n",
    "else:\n",
    "    print(\"Some errors occurred while copying headers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2e7c5-be28-4c7e-90f0-995911eca15a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Filling missing weeks\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Some years have 1 week more than others.\n",
    "<br>\n",
    "This gaps are filled with the data of subsequents years in each column.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "338afce5-6b92-4322-ba19-fc95b58324cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/Raw_Data.csv\n",
      "Processing completed successfully for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/Raw_Data.csv\n",
      "Overall processing finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1537771' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1530559' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4266060' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2156583' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9429185' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3410560' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2736874' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '781990' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3216474' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '354' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5679' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '51945281' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2174000' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '17532000' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
      "/tmp/ipykernel_69186/3084917098.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
      "/tmp/ipykernel_69186/3084917098.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2600' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n"
     ]
    }
   ],
   "source": [
    "# Read the reference data CSV file\n",
    "#reference_data_file_path = \"/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Reference_Data.csv\"\n",
    "df_reference = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Iterate through each zone and its folder path\n",
    "for index, row in df_reference.iterrows():\n",
    "    raw_data_file_path = row[\"Raw_Data_File_Path\"]\n",
    "\n",
    "    # Read the zone's CSV data (handle potential file not found)\n",
    "    if os.path.exists(raw_data_file_path):\n",
    "        df = pd.read_csv(raw_data_file_path)\n",
    "    else:\n",
    "        print(f\"File not found: {raw_data_file_path}\")\n",
    "        continue  # Skip to the next zone if file is missing\n",
    "\n",
    "    # Process the data (add new row, fill missing values)\n",
    "    df.loc[len(df)] = ['Week 54'] + [None] * (len(df.columns) - 1)\n",
    "    for col in df.columns[1:]:\n",
    "        penultimate_value = df.iloc[-2][col]\n",
    "        last_value = df.iloc[-1][col]\n",
    "\n",
    "        if pd.isna(penultimate_value):\n",
    "            next_col_index = df.columns.get_loc(col) + 1\n",
    "            if next_col_index < len(df.columns):\n",
    "                next_col_name = df.columns[next_col_index]\n",
    "                next_col_first_value = df.iloc[0][next_col_name]\n",
    "                df.iloc[-2, df.columns.get_loc(col)] = next_col_first_value\n",
    "\n",
    "        if pd.isna(last_value):\n",
    "            next_col_index = df.columns.get_loc(col) + 1\n",
    "            if next_col_index < len(df.columns):\n",
    "                next_col_name = df.columns[next_col_index]\n",
    "                next_col_second_value = df.iloc[1][next_col_name]\n",
    "                df.iloc[-1, df.columns.get_loc(col)] = next_col_second_value\n",
    "\n",
    "    # Save the modified DataFrame back to the CSV file\n",
    "    df.to_csv(raw_data_file_path, index=False)\n",
    "\n",
    "    print(f\"Processing completed successfully for file: {raw_data_file_path}\")\n",
    "\n",
    "print(\"Overall processing finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ebd57-d03f-499a-b207-ff1862b96d4d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Filling empty N/A or n/e fields\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Some years have no data in their columns so this are replaced by '0'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de6d12e0-4346-4ac3-ab7f-465874c7438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/Raw_Data.csv\n",
      "Replaced 2 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/Raw_Data.csv\n",
      "Replaced 486 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/Raw_Data.csv\n",
      "Replaced 4 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/Raw_Data.csv\n",
      "Replaced 2 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/Raw_Data.csv\n",
      "Replaced 465 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/Raw_Data.csv\n",
      "Replaced 486 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/Raw_Data.csv\n",
      "Replaced 486 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/Raw_Data.csv\n",
      "Replaced 486 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/Raw_Data.csv\n",
      "Replaced 486 values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1241220224.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"n/e\", 0.0)\n",
      "/tmp/ipykernel_69186/1241220224.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"n/e\", 0.0)\n",
      "/tmp/ipykernel_69186/1241220224.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"n/e\", 0.0)\n",
      "/tmp/ipykernel_69186/1241220224.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"n/e\", 0.0)\n",
      "/tmp/ipykernel_69186/1241220224.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"n/e\", 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/Raw_Data.csv\n",
      "Replaced 99 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/Raw_Data.csv\n",
      "Replaced 2 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/Raw_Data.csv\n",
      "Replaced 3 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/Raw_Data.csv\n",
      "Replaced 4 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/Raw_Data.csv\n",
      "Replaced 2 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/Raw_Data.csv\n",
      "Replaced 486 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/Raw_Data.csv\n",
      "Replaced 486 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/Raw_Data.csv\n",
      "Replaced 3 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/Raw_Data.csv\n",
      "Replaced 3 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/Raw_Data.csv\n",
      "Replaced 486 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/Raw_Data.csv\n",
      "Replaced 2 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/Raw_Data.csv\n",
      "Replaced 486 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/Raw_Data.csv\n",
      "Replaced 486 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/Raw_Data.csv\n",
      "Replaced 3 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/Raw_Data.csv\n",
      "Replaced 486 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/Raw_Data.csv\n",
      "Replaced 486 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/Raw_Data.csv\n",
      "Replaced 2 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/Raw_Data.csv\n",
      "Replaced 4 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/Raw_Data.csv\n",
      "Replaced 6 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/Raw_Data.csv\n",
      "Replaced 465 values.\n",
      "Processed CSV file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/Raw_Data.csv\n",
      "Replaced 486 values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1241220224.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"n/e\", 0.0)\n",
      "/tmp/ipykernel_69186/1241220224.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"n/e\", 0.0)\n",
      "/tmp/ipykernel_69186/1241220224.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"n/e\", 0.0)\n",
      "/tmp/ipykernel_69186/1241220224.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"n/e\", 0.0)\n",
      "/tmp/ipykernel_69186/1241220224.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"n/e\", 0.0)\n",
      "/tmp/ipykernel_69186/1241220224.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"n/e\", 0.0)\n",
      "/tmp/ipykernel_69186/1241220224.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"n/e\", 0.0)\n",
      "/tmp/ipykernel_69186/1241220224.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"n/e\", 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Read the reference data CSV file\n",
    "reference_data = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Iterate through each row in the \"Raw_Data_File_Path\" column\n",
    "for index, row in reference_data.iterrows():\n",
    "    raw_data_file_path = row[\"Raw_Data_File_Path\"]\n",
    "\n",
    "    # Read the raw data CSV file\n",
    "    raw_data = pd.read_csv(raw_data_file_path)\n",
    "\n",
    "    # Select columns from the second column onwards\n",
    "    columns_to_process = raw_data.columns[1:]\n",
    "\n",
    "    # Replace empty values, 'N/A', and 'n/e' with '0.0' in the selected columns\n",
    "    before_replace = raw_data[columns_to_process].isnull().sum().sum() + raw_data[columns_to_process].isin([\"N/A\", \"n/e\"]).sum().sum()\n",
    "    raw_data[columns_to_process] = raw_data[columns_to_process].fillna(0.0)\n",
    "    raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"N/A\", 0.0)\n",
    "    raw_data[columns_to_process] = raw_data[columns_to_process].replace(\"n/e\", 0.0)\n",
    "    after_replace = raw_data[columns_to_process].isnull().sum().sum() + raw_data[columns_to_process].isin([\"N/A\", \"n/e\"]).sum().sum()\n",
    "    replaced_values = before_replace - after_replace\n",
    "\n",
    "    # Process the cleaned raw data as needed\n",
    "    # ...\n",
    "\n",
    "    # Save the modified raw data to the original CSV file\n",
    "    raw_data.to_csv(raw_data_file_path, index=False)\n",
    "\n",
    "    # Print a message indicating the processed file and replaced values\n",
    "    print(f\"Processed CSV file: {raw_data_file_path}\")\n",
    "    print(f\"Replaced {replaced_values} values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70f1998-a67e-44b2-8438-7aece9be4ae5",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Separating the raw data by interested year.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "The raw data content reservoir level information of many years (from the 'start_year' variable to the 'end_year' variable).\n",
    "<br>\n",
    "The data belonged to the year defined by the 'data_year' variable is separated to be processed and are saved in a csv file named as the 'data_year' variable plus '_1.csv' e.g. 2023_1.csv\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcf50f65-9493-4c03-8107-7d44fd8d47e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/2023_1.csv\n",
      "Data extracted and saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/2023_1.csv\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file containing the file paths\n",
    "#reference_data_file_path = \"/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Reference_Data.csv\"\n",
    "df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Iterate over each file path in the 'Raw_Data_File_Path' column\n",
    "for file_path in df['Raw_Data_File_Path']:\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Define the new file name\n",
    "        new_file_name = 'Raw_Data.csv'\n",
    "        new_file_path = os.path.join(os.path.dirname(file_path), new_file_name)\n",
    "\n",
    "        # Rename the original file\n",
    "        os.rename(file_path, new_file_path)\n",
    "\n",
    "        # Read the original CSV file\n",
    "        df_original = pd.read_csv(new_file_path)\n",
    "\n",
    "        # Extract the first column and the column with the same value as data_year\n",
    "        new_df = df_original[['Week', str(data_year)]]\n",
    "\n",
    "        # Define the new file name for the extracted data\n",
    "        new_file_name_extracted = f\"{data_year}_1.csv\"\n",
    "        new_file_path_extracted = os.path.join(os.path.dirname(file_path), new_file_name_extracted)\n",
    "\n",
    "        # Save the extracted data to a new CSV file\n",
    "        new_df.to_csv(new_file_path_extracted, index=False)\n",
    "\n",
    "        print(f\"Data extracted and saved to {new_file_path_extracted}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"File '{file_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6513f4-9f7d-4694-b2a6-3490b8cea848",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Adding columns to the reference_data file that define the path to the final processed time series reservoir files according its time step.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "This columns are needed in the next stages of the code\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96375cda-a743-4dfd-8990-e60731633565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New headers added to the reference data file.\n"
     ]
    }
   ],
   "source": [
    "# Read the reference data CSV file\n",
    "df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Add new headers\n",
    "new_headers = ['1h', '30min', '15min']\n",
    "df = pd.concat([df, pd.DataFrame(columns=new_headers)], axis=1)\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df.to_csv(reference_data_file_path, index=False)\n",
    "\n",
    "print(\"New headers added to the reference data file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb213b1-01d5-42bd-9c3c-6b38c519e6fb",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 17px; font-family: TimesNewRoman; color:skyblue\">\n",
    "6.2. Reservoir Level Factor\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Getting the corresponding reservoir level factor to the extracted raw data files.\n",
    "<br>\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "As the full storage capacity of each HPSP and HDAM unit it is not provided by the web source. \n",
    "<br>\n",
    "It is going to work with the maximum agregated Storage Energy Value of the corresponding year i.e. defined in the data_year variable.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15cf62fc-d809-4b46-a681-fbbd095091fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/2023_1.csv\n",
      "Filled column with zeros for file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/2023_1.csv\n",
      "Processed and normalized file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/2023_1.csv\n",
      "Updated reference data saved to: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Reference_Data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_69186/3430833264.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[str(data_year)].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def normalize_column(data_year, reference_data_file_path):\n",
    "    \"\"\"Normalize the specified column in each CSV file by dividing by the maximum value.\n",
    "       The maximum value is saved in a new column named 'Maximum_Level' in the reference DataFrame.\n",
    "       If the maximum value is 0 or the column contains non-numeric values, it will be filled with zeros.\"\"\"\n",
    "    \n",
    "    # Read the reference data file\n",
    "    df_reference = pd.read_csv(reference_data_file_path)\n",
    "    \n",
    "    for index, row in df_reference.iterrows():\n",
    "        # Construct the path to the folder and the corresponding CSV file\n",
    "        folder_path = row['Zone_Folder_Path']\n",
    "        csv_file_path = os.path.join(folder_path, f\"{data_year}_1.csv\")\n",
    "        \n",
    "        # Check if the CSV file exists\n",
    "        if os.path.exists(csv_file_path):\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "            \n",
    "            if str(data_year) in df.columns:\n",
    "                # Convert the column to numeric, replacing non-numeric values with NaN\n",
    "                df[str(data_year)] = pd.to_numeric(df[str(data_year)], errors='coerce')\n",
    "                \n",
    "                # Find the maximum value in the column, ignoring NaN values\n",
    "                max_value = df[str(data_year)].max()\n",
    "                \n",
    "                if pd.notna(max_value) and max_value != 0:  # Avoid division by zero\n",
    "                    # Normalize the column by dividing each value by the maximum value\n",
    "                    df[str(data_year)] = df[str(data_year)] / max_value\n",
    "                else:\n",
    "                    # If max_value is NaN or zero, set max_value to 0 and fill the column with zeros\n",
    "                    max_value = 0\n",
    "                    df[str(data_year)].fillna(0, inplace=True)\n",
    "                    print(f\"Filled column with zeros for file: {csv_file_path}\")\n",
    "                \n",
    "                # Save the maximum value in the 'Maximum_Level' column of df_reference\n",
    "                df_reference.at[index, 'Maximum_Level'] = max_value\n",
    "                \n",
    "                # Save the updated CSV file\n",
    "                df.to_csv(csv_file_path, index=False)\n",
    "                \n",
    "                # Print a message indicating that the file was processed\n",
    "                print(f\"Processed and normalized file: {csv_file_path}\")\n",
    "            else:\n",
    "                print(f\"Column {data_year} not found in {csv_file_path}\")\n",
    "                # Ensure the 'Maximum_Level' is set to 0 in df_reference if the column is not found\n",
    "                df_reference.at[index, 'Maximum_Level'] = 0\n",
    "        else:\n",
    "            print(f\"File not found: {csv_file_path}\")\n",
    "            # Ensure the 'Maximum_Level' is set to 0 in df_reference if the file is not found\n",
    "            df_reference.at[index, 'Maximum_Level'] = 0\n",
    "    \n",
    "    # Save the updated reference data with the 'Maximum_Level' column\n",
    "    df_reference.to_csv(reference_data_file_path, index=False)\n",
    "    print(f\"Updated reference data saved to: {reference_data_file_path}\")\n",
    "\n",
    "normalize_column(data_year, reference_data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a8649-6237-47e1-a7f9-8ad2612bdc2b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Getting the corresponding time format.\n",
    "<div/>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "As the full storage capacity data for all the countries are given by a time resolution of a week i.e. 53/54 weeks per year. So it is going to add the corresponding date to each week according to the analized year i.e. value specified in the data_year variable.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9118d794-484f-4033-bd6c-273bdae23ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/2023_1.csv'\n",
      "Processed CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/2023_1.csv'\n",
      "Processing completed for all CSV files.\n"
     ]
    }
   ],
   "source": [
    "# Read the reference data CSV file\n",
    "df_reference = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_reference.iterrows():\n",
    "    raw_data_file_path = row['Single_Raw_Data_File_Path']\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(raw_data_file_path)\n",
    "\n",
    "    # Extract week number from the 'Week' column\n",
    "    df['Week'] = df['Week'].str.extract(r'(\\d+)').astype(int)  # Extract digits from the string and convert to int\n",
    "\n",
    "    # Calculate the dates\n",
    "    start_date = pd.to_datetime(f'{data_year}-01-01')  # Start from January 1st of the specified year\n",
    "    df['Dispa-SET_Date'] = start_date + pd.to_timedelta((df['Week'] - 1) * 7, unit='D')  # Add the corresponding number of weeks\n",
    "\n",
    "    # Convert to string in the desired format\n",
    "    df['Dispa-SET_Date'] = df['Dispa-SET_Date'].dt.strftime('%Y-%m-%d 00:00:00+00:00')\n",
    "\n",
    "    # Save the modified DataFrame back to the CSV file\n",
    "    df.to_csv(raw_data_file_path, index=False)\n",
    "\n",
    "    print(f\"Processed CSV file '{raw_data_file_path}'\")\n",
    "\n",
    "print(\"Processing completed for all CSV files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd1b04-f91a-4083-84ee-764d5359493d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right; margin-left: 3.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    Tracking Variables. \n",
    "    <br>\n",
    "    <div style=\"text-align: right; margin-left: 1.50em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    This cells are just to confirm all the file names, file paths and other information related to the data being processed.\n",
    "    <br>\n",
    "  Also are used to ensure the inputs for next cells in order to avoid to re-enter the same information each time.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c59fee2-60b3-4c40-a825-674583b82068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispaSET_unleash_folder_name:                              Dispa-SET_Unleash\n",
      "dispaSET_unleash_folder_path:                              /home/ray/Dispa-SET_Unleash\n",
      "data_year:                                                 2023\n",
      "reference_data_folder_path:                                /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/\n",
      "reference_data_file_name:                                  Reference_Data.csv\n",
      "reference_data_file_path:                                  /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Reference_Data.csv\n",
      "reservoir_level_folder_path:                               /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/\n",
      "reservoir_level_raw_data_folder_path:                      /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Series_Raw_Data_Source/\n",
      "standard_time:                                             UTC\n"
     ]
    }
   ],
   "source": [
    "print (f\"dispaSET_unleash_folder_name:                              {dispaSET_unleash_folder_name}\")\n",
    "print (f\"dispaSET_unleash_folder_path:                              {dispaSET_unleash_folder_path}\")\n",
    "print (f\"data_year:                                                 {data_year}\")\n",
    "print (f\"reference_data_folder_path:                                {reference_data_folder_path}\")\n",
    "print (f\"reference_data_file_name:                                  {reference_data_file_name}\")\n",
    "print (f\"reference_data_file_path:                                  {reference_data_file_path}\")\n",
    "print (f\"reservoir_level_folder_path:                               {reservoir_level_folder_path}\")\n",
    "print (f\"reservoir_level_raw_data_folder_path:                      {reservoir_level_raw_data_folder_path}\")\n",
    "print (f\"standard_time:                                             {standard_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d24888-ee39-42af-9c1d-a96558ee617f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 17px; font-family: TimesNewRoman; color:skyblue\">\n",
    "6.3. Time Step\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Since the raw data is given by week, it is needed interpolate the values throughout a whole year.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "For this purpouse the raw that from the availability factor folders is used.\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Defining needed variables.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2522e796-92fb-4c33-83d0-b8d876df7108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_rata_source_folder_path: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/\n"
     ]
    }
   ],
   "source": [
    "# Additional string to be appended\n",
    "additional_path_3 = \"/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/\"\n",
    "\n",
    "# Construct the Raw Data Source variable\n",
    "raw_rata_source_folder_path = dispaSET_unleash_folder_path + additional_path_3\n",
    "\n",
    "print(\"raw_rata_source_folder_path:\", raw_rata_source_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682cdba5-91d7-4fb3-bdc8-6921dc35167f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 16px; font-family: TimesNewRoman; color:skyblue\">\n",
    "6.3.1. Reference Raw Data for Time Step \n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color: skyblue\">\n",
    "Writting the 'Time_Series_Raw_Data_File_Path' column to the 'reference_data_file_path' file.\n",
    "<br>\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color: skyblue\">\n",
    "This columns specify the path to the corresponding raw data csv file sources.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c37575bf-34d4-42a6-b113-e8a24a588cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV file saved to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Reference_Data.csv\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Create the new column with the required file paths\n",
    "df['Time_Series_Raw_Data_File_Path'] = df.apply(\n",
    "    lambda row: f\"{raw_rata_source_folder_path}{standard_time}/{row['Dispa-SET_Code']}/{data_year}_1.csv\", axis=1)\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "df.to_csv(reference_data_file_path, index=False)\n",
    "\n",
    "print(f\"Updated CSV file saved to {reference_data_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf468129-b314-4faa-9980-c098ea8cb3bd",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color: skyblue\">\n",
    "Extracting the corresponding raw data time step reference file to be processed.\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color: skyblue\">\n",
    "Updating the 'Time_Series_Raw_Data_File_Path' column of the 'reference_data_file_path' with the extracted raw data csv file sources paths.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccb75b88-e0ed-4a9b-a22e-2d8e4f6d48e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/AT/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/AT/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/BE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/BE/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/BG/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/BG/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/CH/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CH/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/CY/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CY/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/CZ/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CZ/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/DE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DE/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/DK/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DK/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/EE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EE/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/EL/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EL/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/ES/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/ES/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/FI/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/FI/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/FR/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/FR/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/HR/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HR/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/HU/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HU/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/IE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IE/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/IT/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IT/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/LT/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LT/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/LU/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LU/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/LV/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LV/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/MT/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/MT/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/NL/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NL/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/NO/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NO/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/PL/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/PL/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/PT/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/PT/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/RO/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/RO/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/SE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SE/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/SI/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SI/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/SK/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SK/2023_1.csv\n",
      "Copying file: /home/ray/Dispa-SET_Unleash/RawData/AvailabilityFactors/Time_Series_Raw_Data_Source/UTC/UK/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/UK/2023_1.csv\n"
     ]
    }
   ],
   "source": [
    "def copy_and_organize_files(reference_data_file_path, reference_data_folder_path):\n",
    "    \"\"\"Copies and organizes CSV files based on information in a CSV file.\n",
    "\n",
    "    Args:\n",
    "        reference_data_file_path: Path to the CSV file containing file paths and codes.\n",
    "        reference_data_folder_path: Path to the destination folder.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Get the source file path and Dispa-SET code\n",
    "        source_file_path = row['Time_Series_Raw_Data_File_Path']\n",
    "        dispa_set_code = row['Dispa-SET_Code']\n",
    "\n",
    "        # Construct the destination folder path\n",
    "        destination_folder = os.path.join(reference_data_folder_path, \"Time_Step_Data_Reference\", dispa_set_code)\n",
    "\n",
    "        # Create the destination folder if it doesn't exist\n",
    "        if not os.path.exists(destination_folder):\n",
    "            os.makedirs(destination_folder)\n",
    "\n",
    "        # Construct the full destination file path\n",
    "        destination_file_path = os.path.join(destination_folder, os.path.basename(source_file_path))\n",
    "\n",
    "        # Copy the file from the source to the destination\n",
    "        print(f\"Copying file: {source_file_path} to {destination_file_path}\")\n",
    "        shutil.copy2(source_file_path, destination_file_path)\n",
    "\n",
    "        # Update the DataFrame with the new file path\n",
    "        df.at[index, 'Time_Series_Raw_Data_File_Path'] = destination_file_path\n",
    "\n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df.to_csv(reference_data_file_path, index=False)\n",
    "\n",
    "# Example usage\n",
    "copy_and_organize_files(reference_data_file_path, reference_data_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192b8934-e999-41ea-942c-82636cf45fa5",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Writing to the 'reference_data_file_path' the path to the country folders that content all the data realted to the time step reference file in order to use them for next processing stages.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "244c3d26-1956-49d9-a82a-449ef7bd2c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted zone folder path for row 0: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/AT\n",
      "Extracted zone folder path for row 1: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/BE\n",
      "Extracted zone folder path for row 2: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/BG\n",
      "Extracted zone folder path for row 3: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CH\n",
      "Extracted zone folder path for row 4: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CY\n",
      "Extracted zone folder path for row 5: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CZ\n",
      "Extracted zone folder path for row 6: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DE\n",
      "Extracted zone folder path for row 7: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DK\n",
      "Extracted zone folder path for row 8: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EE\n",
      "Extracted zone folder path for row 9: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EL\n",
      "Extracted zone folder path for row 10: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/ES\n",
      "Extracted zone folder path for row 11: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/FI\n",
      "Extracted zone folder path for row 12: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/FR\n",
      "Extracted zone folder path for row 13: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HR\n",
      "Extracted zone folder path for row 14: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HU\n",
      "Extracted zone folder path for row 15: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IE\n",
      "Extracted zone folder path for row 16: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IT\n",
      "Extracted zone folder path for row 17: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LT\n",
      "Extracted zone folder path for row 18: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LU\n",
      "Extracted zone folder path for row 19: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LV\n",
      "Extracted zone folder path for row 20: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/MT\n",
      "Extracted zone folder path for row 21: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NL\n",
      "Extracted zone folder path for row 22: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NO\n",
      "Extracted zone folder path for row 23: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/PL\n",
      "Extracted zone folder path for row 24: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/PT\n",
      "Extracted zone folder path for row 25: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/RO\n",
      "Extracted zone folder path for row 26: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SE\n",
      "Extracted zone folder path for row 27: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SI\n",
      "Extracted zone folder path for row 28: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SK\n",
      "Extracted zone folder path for row 29: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/UK\n"
     ]
    }
   ],
   "source": [
    "def extract_zone_folder_paths(reference_data_file_path, data_year):\n",
    "    \"\"\"Extracts zone folder paths and creates a new column in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        reference_data_file_path (str): Path to the reference data CSV file.\n",
    "        data_year (str): The year for the target CSV files.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        file_path = row['Time_Series_Raw_Data_File_Path']\n",
    "        zone_folder_path = os.path.dirname(file_path)\n",
    "        df.at[index, 'Time_Step_Reference_Zone_Folder_Path'] = zone_folder_path\n",
    "        print(f\"Extracted zone folder path for row {index}: {zone_folder_path}\")\n",
    "\n",
    "    df.to_csv(reference_data_file_path, index=False)\n",
    "\n",
    "extract_zone_folder_paths(reference_data_file_path, data_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d594d-868a-4883-8a77-4ed5d9447b0b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 16px; font-family: TimesNewRoman; color:skyblue\">\n",
    "    6.3.2. Time Step Reference Data Processing\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color: skyblue\">\n",
    "Adding column names.\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color: skyblue\">\n",
    "All the time step reference data were downloaded without columns identification, the corresponding header to each column is added.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b44c912-d233-441f-8fe0-0e236c13d4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/AT/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/BE/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/BG/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CH/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CY/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CZ/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DE/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DK/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EE/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EL/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/ES/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/FI/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/FR/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HR/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HU/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IE/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IT/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LT/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LU/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LV/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/MT/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NL/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NO/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/PL/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/PT/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/RO/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SE/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SI/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SK/2023_1.csv'.\n",
      "Empty row added at the beginning of file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/UK/2023_1.csv'.\n",
      "Empty rows added and headers copied successfully to the first empty row of all files.\n"
     ]
    }
   ],
   "source": [
    "# Define the headers\n",
    "headers = [\n",
    "    \"MTU\", \"Biomass_Actual_Aggregated\", \"Biomass_Actual_Consumption\",\n",
    "    \"Fossil_Brown_coal-Lignite_Actual_Aggregated\", \"Fossil_Brown_coal-Lignite_Actual_Consumption\",\n",
    "    \"Fossil_Coal-derived_gas_Actual_Aggregated\", \"Fossil_Coal-derived_gas_Actual_Consumption\",\n",
    "    \"Fossil_Gas_Actual_Aggregated\", \"Fossil_Gas_Actual_Consumption\",\n",
    "    \"Fossil_Hard_coal_Actual_Aggregated\", \"Fossil_Hard_coal_Actual_Consumption\",\n",
    "    \"Fossil_Oil_Actual_Aggregated\", \"Fossil_Oil_Actual_Consumption\",\n",
    "    \"Fossil_Oil_shale_Actual_Aggregated\", \"Fossil_Oil_shale_Actual_Consumption\",\n",
    "    \"Fossil_Peat_Actual_Aggregated\", \"Fossil_Peat_Actual_Consumption\",\n",
    "    \"Geothermal_Actual_Aggregated\", \"Geothermal_Actual_Consumption\",\n",
    "    \"Hydro_Pumped_Storage_Actual_Aggregated\", \"Hydro_Pumped_Storage_Actual_Consumption\",\n",
    "    \"Hydro_Run-of-river_and_poundage_Actual_Aggregated\", \"Hydro_Run-of-river_and_poundage_Actual_Consumption\",\n",
    "    \"Hydro_Water_Reservoir_Actual_Aggregated\", \"Hydro_Water_Reservoir_Actual_Consumption\",\n",
    "    \"Marine_Actual_Aggregated\", \"Marine_Actual_Consumption\",\n",
    "    \"Nuclear_Actual_Aggregated\", \"Nuclear_Actual_Consumption\",\n",
    "    \"Other_Actual_Aggregated\", \"Other_Actual_Consumption\",\n",
    "    \"Other_renewable_Actual_Aggregated\", \"Other_renewable_Actual_Consumption\",\n",
    "    \"Solar_Actual_Aggregated\", \"Solar_Actual_Consumption\",\n",
    "    \"Waste_Actual_Aggregated\", \"Waste_Actual_Consumption\",\n",
    "    \"Wind_Offshore_Actual_Aggregated\", \"Wind_Offshore_Actual_Consumption\",\n",
    "    \"Wind_Onshore_Actual_Aggregated\", \"Wind_Onshore_Actual_Consumption\"\n",
    "]\n",
    "\n",
    "# Read the CSV file containing the paths\n",
    "df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "success = True\n",
    "\n",
    "# Iterate through each file path in the column 'Time_Series_Raw_Data_File_Path'\n",
    "for index, row in df.iterrows():\n",
    "    file_path = row['Time_Series_Raw_Data_File_Path']\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Open the existing CSV file in read mode\n",
    "        with open(file_path, 'r', newline='') as file:\n",
    "            # Read the existing content\n",
    "            reader = csv.reader(file)\n",
    "            rows = list(reader)\n",
    "\n",
    "        # Insert a new empty row at the beginning\n",
    "        rows.insert(0, [])\n",
    "\n",
    "        # Write the updated content back to the CSV file\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(rows)\n",
    "        \n",
    "        print(f\"Empty row added at the beginning of file '{file_path}'.\")\n",
    "\n",
    "        # Read the file content again after adding the empty row\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Find the index of the first empty row\n",
    "        empty_row_index = next((i for i, line in enumerate(lines) if line.strip() == \"\"), None)\n",
    "\n",
    "        # If an empty row is found, copy the headers to it\n",
    "        if empty_row_index is not None:\n",
    "            lines[empty_row_index] = ','.join(headers) + '\\n'\n",
    "\n",
    "            # Write the updated lines back to the file\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.writelines(lines)\n",
    "        else:\n",
    "            print(f\"No empty row found in file '{file_path}'. Headers not copied.\")\n",
    "    else:\n",
    "        success = False\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "if success:\n",
    "    print(\"Empty rows added and headers copied successfully to the first empty row of all files.\")\n",
    "else:\n",
    "    print(\"Some errors occurred while processing the files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3a674b-7e90-4973-a89e-e11092dafc1e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 17px; font-family: TimesNewRoman; color: skyblue\">\n",
    "6.3.3. Time Step Reference Data Time Resolution\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color: skyblue\">\n",
    "Identifying the time spept of all the reference data files.\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color: skyblue\">\n",
    "Additional columns that indicates the Year, Mounth, Day, Hour and minute of the data are added to the files.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a51a320b-7f34-4969-a4f0-d54fbaa2e239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/AT/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/BE/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/BG/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CH/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CY/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CZ/2023_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1429228844.py:14: DtypeWarning: Columns (27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  file_df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DE/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DK/2023_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1429228844.py:14: DtypeWarning: Columns (27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  file_df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EE/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EL/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/ES/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/FI/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/FR/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HR/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HU/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IE/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IT/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LT/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LU/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LV/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/MT/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NL/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NO/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/PL/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/PT/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/RO/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SE/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SI/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SK/2023_1.csv\n",
      "Updated file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/UK/2023_1.csv\n",
      "All files updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file containing the paths\n",
    "df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Function to validate and convert MTU parts to integers\n",
    "def safe_int_conversion(value):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        return None  # or some default value like 0\n",
    "\n",
    "# Iterate through each file path in the 'Time_Series_Raw_Data_File_Path' column\n",
    "for file_path in df['Time_Series_Raw_Data_File_Path']:\n",
    "    # Read the CSV file\n",
    "    file_df = pd.read_csv(file_path)\n",
    "\n",
    "    # Add new columns 'Year', 'Month', 'Day', 'Hour', and 'Minute'\n",
    "    file_df['Year'] = data_year\n",
    "    file_df['Month'] = ''\n",
    "    file_df['Day'] = ''\n",
    "\n",
    "    # Ensure the 'MTU' column is treated as a string and is 5 characters long\n",
    "    if file_df['MTU'].dtype != 'object':\n",
    "        file_df['MTU'] = file_df['MTU'].astype(str)\n",
    "\n",
    "    # Ensure all strings in 'MTU' column are at least 5 characters long\n",
    "    file_df['MTU'] = file_df['MTU'].str.zfill(5)\n",
    "\n",
    "    # Extract hour and minute from 'MTU' column with safe conversion\n",
    "    file_df['Hour'] = file_df['MTU'].str[:2].apply(safe_int_conversion)\n",
    "    file_df['Minute'] = file_df['MTU'].str[3:5].apply(safe_int_conversion)\n",
    "\n",
    "    # Reorder the columns to have 'Year', 'Month', 'Day', 'Hour', and 'Minute' first\n",
    "    file_df = file_df[['Year', 'Month', 'Day', 'Hour', 'Minute'] + [col for col in file_df.columns if col not in ['Year', 'Month', 'Day', 'Hour', 'Minute']]]\n",
    "\n",
    "    # Write the updated DataFrame back to the CSV file\n",
    "    file_df.to_csv(file_path, index=False)\n",
    "\n",
    "    print(f\"Updated file: {file_path}\")\n",
    "\n",
    "print(\"All files updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c8a639-553e-4ccb-a41a-4220aa0362cc",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Extracting the time stept data.\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "The rows corresponding to a time resolution of 1 hour, 30 minutes and 15 minutes are extracted and added to new files with the suffix _1h, _30min, and _15min.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb6e6e31-55ac-4ee6-a14d-1425703c9bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/AT/2023_1.csv\n",
      "File has 35040 or 34544 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/BE/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/BG/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CH/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CY/2023_1.csv\n",
      "File has 17520 or 17522 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CZ/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DE/2023_1.csv\n",
      "File has 35040 or 34544 rows. Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/953703549.py:5: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DK/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EE/2023_1.csv\n",
      "File has 35040 or 34544 rows. Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/953703549.py:5: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EL/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/ES/2023_1.csv\n",
      "File has 35040 or 34544 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/FI/2023_1.csv\n",
      "File has 24960 rows. No specific conditions matched. Processing as default...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/FR/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HR/2023_1.csv\n",
      "File has 11064 rows. No specific conditions matched. Processing as default...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HU/2023_1.csv\n",
      "File has 35040 or 34544 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IE/2023_1.csv\n",
      "File has 17520 or 17522 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IT/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LT/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LU/2023_1.csv\n",
      "File has 35040 or 34544 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LV/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/MT/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NL/2023_1.csv\n",
      "File has 35040 or 34544 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NO/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/PL/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/PT/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/RO/2023_1.csv\n",
      "File has 35040 or 34544 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SE/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SI/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SK/2023_1.csv\n",
      "File has 8760 or 8761 rows. Processing...\n",
      "Processed successfully.\n",
      "Processing file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/UK/2023_1.csv\n",
      "File has 17520 or 17522 rows. Processing...\n",
      "Processed successfully.\n"
     ]
    }
   ],
   "source": [
    "def process_csv_file(csv_file_path):\n",
    "    print(f\"Processing file: {csv_file_path}\")\n",
    "    \n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Count the number of rows\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    # Define file name without extension\n",
    "    file_name_no_ext = os.path.splitext(os.path.basename(csv_file_path))[0]\n",
    "    \n",
    "    # Get the directory of the current CSV file\n",
    "    base_dir = os.path.dirname(csv_file_path)\n",
    "    \n",
    "    # Check conditions and process accordingly\n",
    "    if num_rows in [35040, 35136, 34544]:\n",
    "        print(f\"File has 35040 or 34544 rows. Processing...\")\n",
    "        process_35040_34544(df, file_name_no_ext, base_dir)\n",
    "    elif num_rows in [17520, 17522, 17568, 17570]:\n",
    "        print(f\"File has 17520 or 17522 rows. Processing...\")\n",
    "        process_17520_17522(df, file_name_no_ext, base_dir)\n",
    "    elif num_rows in [8760, 8761, 8784, 8785]:\n",
    "        print(f\"File has 8760 or 8761 rows. Processing...\")\n",
    "        process_8760_8761(df, file_name_no_ext, base_dir)\n",
    "    else:\n",
    "        print(f\"File has {num_rows} rows. No specific conditions matched. Processing as default...\")\n",
    "        process_default(df, file_name_no_ext, base_dir)\n",
    "\n",
    "def process_35040_34544(df, file_name_no_ext, base_dir):\n",
    "    # Create new file paths\n",
    "    suffixes = ['_1h', '_30min', '_15min']\n",
    "    new_file_paths = [os.path.join(base_dir, file_name_no_ext + suffix + '.csv') for suffix in suffixes]\n",
    "    \n",
    "    # Write data to new files\n",
    "    for new_file_path in new_file_paths:\n",
    "        df.to_csv(new_file_path, index=False)\n",
    "    \n",
    "    # Filter rows and write to corresponding files\n",
    "    df_minute_zero = df[df['Minute'] == 0]\n",
    "    df_minute_zero.to_csv(os.path.join(base_dir, file_name_no_ext + '_1h.csv'), index=False)\n",
    "    \n",
    "    df_minute_zero_or_thirty = df[df['Minute'].isin([0, 30])]\n",
    "    df_minute_zero_or_thirty.to_csv(os.path.join(base_dir, file_name_no_ext + '_30min.csv'), index=False)\n",
    "    \n",
    "    print(\"Processed successfully.\")\n",
    "\n",
    "def process_17520_17522(df, file_name_no_ext, base_dir):\n",
    "    # Create new file paths\n",
    "    suffixes = ['_1h', '_30min']\n",
    "    new_file_paths = [os.path.join(base_dir, file_name_no_ext + suffix + '.csv') for suffix in suffixes]\n",
    "    \n",
    "    # Write data to new files\n",
    "    for new_file_path in new_file_paths:\n",
    "        df.to_csv(new_file_path, index=False)\n",
    "    \n",
    "    # Filter rows and write to corresponding files\n",
    "    df_minute_zero = df[df['Minute'] == 0]\n",
    "    df_minute_zero.to_csv(os.path.join(base_dir, file_name_no_ext + '_1h.csv'), index=False)\n",
    "    \n",
    "    print(\"Processed successfully.\")\n",
    "\n",
    "def process_8760_8761(df, file_name_no_ext, base_dir):\n",
    "    # Create new file path\n",
    "    new_file_path = os.path.join(base_dir, file_name_no_ext + '_1h.csv')\n",
    "    \n",
    "    # Write data to new file\n",
    "    df.to_csv(new_file_path, index=False)\n",
    "    \n",
    "    print(\"Processed successfully.\")\n",
    "\n",
    "def process_default(df, file_name_no_ext, base_dir):\n",
    "    # Create new file path\n",
    "    new_file_path = os.path.join(base_dir, file_name_no_ext + '_1h.csv')\n",
    "    \n",
    "    # Filter rows and write to corresponding files\n",
    "    df_minute_zero = df[df['Minute'] == 0]\n",
    "    df_minute_zero.to_csv(os.path.join(base_dir, file_name_no_ext + '_1h.csv'), index=False)\n",
    "    \n",
    "    print(\"Processed successfully.\")\n",
    "\n",
    "# File path\n",
    "#standard_time_data_file_path = \"/home/ray/Dispa-SET_Unleash/RawData/AvailabiltyFactors/Standard_Time_Data.csv\"\n",
    "\n",
    "# Load the CSV file\n",
    "standard_time_data_df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Iterate over each CSV file specified in 'Time_Series_Raw_Data_File_Path'\n",
    "for csv_file_path in standard_time_data_df['Time_Series_Raw_Data_File_Path']:\n",
    "    process_csv_file(csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe08cb9-0f93-427c-a54d-8dd5c9124b15",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Filling the correspondig time stept.\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "For the next stepts of the formating process it is necesary identify the path of the files where all the data of the 30 Dispa-SET countries are going to be storaged differencing them into time stepts (1 hour, 30 min, and 15 min)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fe91cfc-ab7b-47ce-b935-5b1f5effae13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths and variables\n",
    "#standard_time_data_file_path = \"/home/ray/Dispa-SET_Unleash/RawData/AvailabiltyFactors/Standard_Time_Data.csv\"\n",
    "#data_year = 2023\n",
    "\n",
    "# Read the standard time data CSV file\n",
    "df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Define function to search for files in directory\n",
    "def search_files(directory, prefix):\n",
    "    for file in os.listdir(directory):\n",
    "        if file.startswith(prefix):\n",
    "            return os.path.join(directory, file)\n",
    "    return None\n",
    "\n",
    "# Add new columns\n",
    "df[f\"{data_year}_1h_File_Path\"] = \"\"\n",
    "df[f\"{data_year}_30min_File_Path\"] = \"\"\n",
    "df[f\"{data_year}_15min_File_Path\"] = \"\"\n",
    "\n",
    "# Iterate over Zone_Folder_Path column\n",
    "for index, row in df.iterrows():\n",
    "    zone_folder_path = row['Time_Step_Reference_Zone_Folder_Path']\n",
    "    if os.path.exists(zone_folder_path):\n",
    "        # Search for files in the directory\n",
    "        hour_file_path = search_files(zone_folder_path, f\"{data_year}_1_1h.csv\")\n",
    "        if hour_file_path:\n",
    "            df.at[index, f\"{data_year}_1h_File_Path\"] = hour_file_path\n",
    "            \n",
    "        min30_file_path = search_files(zone_folder_path, f\"{data_year}_1_30min.csv\")\n",
    "        if min30_file_path:\n",
    "            df.at[index, f\"{data_year}_30min_File_Path\"] = min30_file_path\n",
    "            \n",
    "        min15_file_path = search_files(zone_folder_path, f\"{data_year}_1_15min.csv\")\n",
    "        if min15_file_path:\n",
    "            df.at[index, f\"{data_year}_15min_File_Path\"] = min15_file_path\n",
    "\n",
    "# Save the updated DataFrame back to the same CSV file\n",
    "df.to_csv(reference_data_file_path, index=False)\n",
    "\n",
    "print(\"CSV file updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1914aea-0ca8-47ba-921b-0e44acc2842a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Fulling the corresponding time step to each file.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Not all the countries have data in a resolution of 15 mimuntes, 30 minutes or 1 hour, so, all the next three cells all the files of the corresponding time stept are going to be fullfilling in their corresponding columns of Minute, Hour, Day and Month of the year specified in the variable data_year.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "<br>\n",
    "1 Hour time stept.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c06b5649-68cc-4de5-8a38-0277f1e2d222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/AT/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/BE/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n",
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n",
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/BG/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CH/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CY/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n",
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n",
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CZ/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DE/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n",
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n",
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DK/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EE/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EL/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n",
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/ES/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/FI/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/FR/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HR/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HU/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IE/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IT/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LT/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LU/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LV/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/MT/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NL/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n",
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NO/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/PL/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/PT/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/RO/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n",
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SE/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SI/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SK/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n",
      "/tmp/ipykernel_69186/3348126855.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/UK/2023_1_1h.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the year\n",
    "year = data_year\n",
    "\n",
    "# Load the CSV file containing paths\n",
    "df_paths = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_paths.iterrows():\n",
    "    # Get the path from the corresponding column\n",
    "    file_path_column_name = f\"{year}_1h_File_Path\"  # Dynamically construct the column name based on the year\n",
    "    file_path = row[file_path_column_name]\n",
    "    \n",
    "    # Check if the path exists and is not NaN\n",
    "    if isinstance(file_path, str) and os.path.exists(file_path):\n",
    "        # Load the existing CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Generate a date range for the entire year\n",
    "        dates = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:00:00', freq='H')\n",
    "\n",
    "        # Extract month, day, and hour from the date range\n",
    "        months = [date.month for date in dates]\n",
    "        days = [date.day for date in dates]\n",
    "        hours = [date.hour % 24 for date in dates]  # Cycle through hours (0-23)\n",
    "\n",
    "        # Update the DataFrame with the generated data\n",
    "        df['Month'] = months\n",
    "        df['Day'] = days\n",
    "        df['Hour'] = hours\n",
    "\n",
    "        # Save the updated DataFrame back to the same CSV file, overwriting the original file\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "        print(f\"CSV file updated successfully: {file_path}\")\n",
    "    else:\n",
    "        print(f\"No valid path specified in row {index + 1}. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4dcd99-40ee-4e58-8bd8-b48989802ec6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "30 Minutes time stept.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05470c25-bdca-46a7-99c3-43c0829a4388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2732984526.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_30min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='30T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 30-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/AT/2023_1_30min.csv\n",
      "No valid path specified in row 2. Skipping...\n",
      "No valid path specified in row 3. Skipping...\n",
      "No valid path specified in row 4. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2732984526.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_30min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='30T')\n",
      "/tmp/ipykernel_69186/2732984526.py:19: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 30-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CY/2023_1_30min.csv\n",
      "No valid path specified in row 6. Skipping...\n",
      "CSV file updated successfully with 30-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DE/2023_1_30min.csv\n",
      "No valid path specified in row 8. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2732984526.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_30min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='30T')\n",
      "/tmp/ipykernel_69186/2732984526.py:19: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/tmp/ipykernel_69186/2732984526.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_30min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='30T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 30-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EE/2023_1_30min.csv\n",
      "No valid path specified in row 10. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2732984526.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_30min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='30T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 30-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/ES/2023_1_30min.csv\n",
      "No valid path specified in row 12. Skipping...\n",
      "No valid path specified in row 13. Skipping...\n",
      "No valid path specified in row 14. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2732984526.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_30min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='30T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 30-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HU/2023_1_30min.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2732984526.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_30min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='30T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 30-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IE/2023_1_30min.csv\n",
      "No valid path specified in row 17. Skipping...\n",
      "No valid path specified in row 18. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2732984526.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_30min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='30T')\n",
      "/tmp/ipykernel_69186/2732984526.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_30min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='30T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 30-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LU/2023_1_30min.csv\n",
      "No valid path specified in row 20. Skipping...\n",
      "No valid path specified in row 21. Skipping...\n",
      "CSV file updated successfully with 30-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NL/2023_1_30min.csv\n",
      "No valid path specified in row 23. Skipping...\n",
      "No valid path specified in row 24. Skipping...\n",
      "No valid path specified in row 25. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2732984526.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_30min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='30T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 30-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/RO/2023_1_30min.csv\n",
      "No valid path specified in row 27. Skipping...\n",
      "No valid path specified in row 28. Skipping...\n",
      "No valid path specified in row 29. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2732984526.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_30min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='30T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 30-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/UK/2023_1_30min.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the year\n",
    "year = data_year\n",
    "\n",
    "# Load the CSV file containing paths\n",
    "#standard_time_data_file_path = \"/home/ray/Dispa-SET_Unleash/RawData/AvailabiltyFactors/Standard_Time_Data.csv\"\n",
    "df_paths = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_paths.iterrows():\n",
    "    # Dynamically construct the column name based on the year\n",
    "    file_path_column_name = f\"{year}_30min_File_Path\"\n",
    "    \n",
    "    # Get the path from the corresponding column\n",
    "    file_path = row[file_path_column_name]\n",
    "    \n",
    "    # Check if the path exists and is not NaN\n",
    "    if isinstance(file_path, str) and os.path.exists(file_path):\n",
    "        # Load the existing CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Generate a date range for the entire year with a time step of 30 minutes\n",
    "        dates_30min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='30T')\n",
    "\n",
    "        # Extract month, day, and hour from the date range with 30-minute time step\n",
    "        months_30min = [date.month for date in dates_30min]\n",
    "        days_30min = [date.day for date in dates_30min]\n",
    "        hours_30min = [date.hour % 24 for date in dates_30min]  # Cycle through hours (0-23)\n",
    "\n",
    "        # Update the DataFrame with the generated data for 30-minute time step\n",
    "        df['Month'] = months_30min\n",
    "        df['Day'] = days_30min\n",
    "        df['Hour'] = hours_30min\n",
    "\n",
    "        # Save the updated DataFrame back to the same CSV file, overwriting the original file\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "        print(f\"CSV file updated successfully with 30-minute time step: {file_path}\")\n",
    "    else:\n",
    "        print(f\"No valid path specified in row {index + 1}. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089a9a8b-0a1c-4143-8e0d-48248c95606a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "15 Minutes time stept.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fca110b7-ef8e-4f57-b01d-25448c47a374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1337634457.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_15min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='15T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 15-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/AT/2023_1_15min.csv\n",
      "No valid path specified in row 2. Skipping...\n",
      "No valid path specified in row 3. Skipping...\n",
      "No valid path specified in row 4. Skipping...\n",
      "No valid path specified in row 5. Skipping...\n",
      "No valid path specified in row 6. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1337634457.py:19: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/tmp/ipykernel_69186/1337634457.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_15min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='15T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 15-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DE/2023_1_15min.csv\n",
      "No valid path specified in row 8. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1337634457.py:19: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/tmp/ipykernel_69186/1337634457.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_15min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='15T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 15-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EE/2023_1_15min.csv\n",
      "No valid path specified in row 10. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1337634457.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_15min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='15T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 15-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/ES/2023_1_15min.csv\n",
      "No valid path specified in row 12. Skipping...\n",
      "No valid path specified in row 13. Skipping...\n",
      "No valid path specified in row 14. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1337634457.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_15min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='15T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 15-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HU/2023_1_15min.csv\n",
      "No valid path specified in row 16. Skipping...\n",
      "No valid path specified in row 17. Skipping...\n",
      "No valid path specified in row 18. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1337634457.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_15min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='15T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 15-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LU/2023_1_15min.csv\n",
      "No valid path specified in row 20. Skipping...\n",
      "No valid path specified in row 21. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1337634457.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_15min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='15T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 15-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NL/2023_1_15min.csv\n",
      "No valid path specified in row 23. Skipping...\n",
      "No valid path specified in row 24. Skipping...\n",
      "No valid path specified in row 25. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1337634457.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_15min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='15T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully with 15-minute time step: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/RO/2023_1_15min.csv\n",
      "No valid path specified in row 27. Skipping...\n",
      "No valid path specified in row 28. Skipping...\n",
      "No valid path specified in row 29. Skipping...\n",
      "No valid path specified in row 30. Skipping...\n"
     ]
    }
   ],
   "source": [
    "# Specify the year\n",
    "year = data_year\n",
    "\n",
    "# Load the CSV file containing paths\n",
    "#standard_time_data_file_path = \"/home/ray/Dispa-SET_Unleash/RawData/AvailabiltyFactors/Standard_Time_Data.csv\"\n",
    "df_paths = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_paths.iterrows():\n",
    "    # Dynamically construct the column name based on the year\n",
    "    file_path_column_name = f\"{year}_15min_File_Path\"\n",
    "    \n",
    "    # Get the path from the corresponding column\n",
    "    file_path = row[file_path_column_name]\n",
    "    \n",
    "    # Check if the path exists and is not NaN\n",
    "    if isinstance(file_path, str) and os.path.exists(file_path):\n",
    "        # Load the existing CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Generate a date range for the entire year with a time step of 15 minutes\n",
    "        dates_15min = pd.date_range(start=f'{year}-01-01 00:00:00', end=f'{year}-12-31 23:59:59', freq='15T')\n",
    "\n",
    "        # Extract month, day, and hour from the date range with 15-minute time step\n",
    "        months_15min = [date.month for date in dates_15min]\n",
    "        days_15min = [date.day for date in dates_15min]\n",
    "        hours_15min = [date.hour % 24 for date in dates_15min]  # Cycle through hours (0-23)\n",
    "\n",
    "        # Update the DataFrame with the generated data for 15-minute time step\n",
    "        df['Month'] = months_15min\n",
    "        df['Day'] = days_15min\n",
    "        df['Hour'] = hours_15min\n",
    "\n",
    "        # Save the updated DataFrame back to the same CSV file, overwriting the original file\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "        print(f\"CSV file updated successfully with 15-minute time step: {file_path}\")\n",
    "    else:\n",
    "        print(f\"No valid path specified in row {index + 1}. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabf3f76-c0dd-45e1-9a6d-acd6db2045ad",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Adding the Dispa-SET Time Stept format.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 1.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "The format that Dispa-SET reads the time stept is the following, 0000-00-00 00:00:00+00:00 where the first part represents the date and the second part represents the time, so the next script add to each row of the correspongind file (1 hour file, 30 minutes file and 15 minutes file for each country) the time stept acording this format.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f83742ba-3644-49ff-a897-ec735f88f01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/AT/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/AT/2023_1_30min.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/AT/2023_1_15min.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/BE/2023_1_1h.csv\n",
      "No valid path specified in row 2. Skipping...\n",
      "No valid path specified in row 2. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/BG/2023_1_1h.csv\n",
      "No valid path specified in row 3. Skipping...\n",
      "No valid path specified in row 3. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CH/2023_1_1h.csv\n",
      "No valid path specified in row 4. Skipping...\n",
      "No valid path specified in row 4. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CY/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CY/2023_1_30min.csv\n",
      "No valid path specified in row 5. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/CZ/2023_1_1h.csv\n",
      "No valid path specified in row 6. Skipping...\n",
      "No valid path specified in row 6. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DE/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2714078988.py:34: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DE/2023_1_30min.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2714078988.py:34: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DE/2023_1_15min.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/DK/2023_1_1h.csv\n",
      "No valid path specified in row 8. Skipping...\n",
      "No valid path specified in row 8. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EE/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2714078988.py:34: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EE/2023_1_30min.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2714078988.py:34: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EE/2023_1_15min.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/EL/2023_1_1h.csv\n",
      "No valid path specified in row 10. Skipping...\n",
      "No valid path specified in row 10. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/ES/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/ES/2023_1_30min.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/ES/2023_1_15min.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/FI/2023_1_1h.csv\n",
      "No valid path specified in row 12. Skipping...\n",
      "No valid path specified in row 12. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/FR/2023_1_1h.csv\n",
      "No valid path specified in row 13. Skipping...\n",
      "No valid path specified in row 13. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HR/2023_1_1h.csv\n",
      "No valid path specified in row 14. Skipping...\n",
      "No valid path specified in row 14. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HU/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HU/2023_1_30min.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/HU/2023_1_15min.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IE/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IE/2023_1_30min.csv\n",
      "No valid path specified in row 16. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/IT/2023_1_1h.csv\n",
      "No valid path specified in row 17. Skipping...\n",
      "No valid path specified in row 17. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LT/2023_1_1h.csv\n",
      "No valid path specified in row 18. Skipping...\n",
      "No valid path specified in row 18. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LU/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LU/2023_1_30min.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LU/2023_1_15min.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/LV/2023_1_1h.csv\n",
      "No valid path specified in row 20. Skipping...\n",
      "No valid path specified in row 20. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/MT/2023_1_1h.csv\n",
      "No valid path specified in row 21. Skipping...\n",
      "No valid path specified in row 21. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NL/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NL/2023_1_30min.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NL/2023_1_15min.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/NO/2023_1_1h.csv\n",
      "No valid path specified in row 23. Skipping...\n",
      "No valid path specified in row 23. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/PL/2023_1_1h.csv\n",
      "No valid path specified in row 24. Skipping...\n",
      "No valid path specified in row 24. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/PT/2023_1_1h.csv\n",
      "No valid path specified in row 25. Skipping...\n",
      "No valid path specified in row 25. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/RO/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/RO/2023_1_30min.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/RO/2023_1_15min.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SE/2023_1_1h.csv\n",
      "No valid path specified in row 27. Skipping...\n",
      "No valid path specified in row 27. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SI/2023_1_1h.csv\n",
      "No valid path specified in row 28. Skipping...\n",
      "No valid path specified in row 28. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/SK/2023_1_1h.csv\n",
      "No valid path specified in row 29. Skipping...\n",
      "No valid path specified in row 29. Skipping...\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/UK/2023_1_1h.csv\n",
      "CSV file updated successfully: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Time_Step_Data_Reference/UK/2023_1_30min.csv\n",
      "No valid path specified in row 30. Skipping...\n"
     ]
    }
   ],
   "source": [
    "# Define a function to create Dispa_SET_Time_Step column\n",
    "def create_Dispa_SET_Time_Step(row):\n",
    "    # Ensure values are integers (or default to 0 if NaN) before formatting\n",
    "    year = int(row['Year']) if pd.notna(row['Year']) else 0\n",
    "    month = int(row['Month']) if pd.notna(row['Month']) else 0\n",
    "    day = int(row['Day']) if pd.notna(row['Day']) else 0\n",
    "    hour = int(row['Hour']) if pd.notna(row['Hour']) else 0\n",
    "    minute = int(row['Minute']) if pd.notna(row['Minute']) else 0\n",
    "    \n",
    "    # Ensure two-digit format for Day, Month, Hour, and Minute\n",
    "    date_part = f\"{year:04d}-{month:02d}-{day:02d}\"\n",
    "    time_part = f\"{hour:02d}:{minute:02d}:00+00:00\"\n",
    "    return date_part + \" \" + time_part\n",
    "\n",
    "# Specify the year\n",
    "#data_year = 2023\n",
    "\n",
    "# Load the CSV file containing file paths\n",
    "#standard_time_data_file_path = \"/home/ray/Dispa-SET_Unleash/RawData/AvailabiltyFactors/Standard_Time_Data.csv\"\n",
    "df_paths = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_paths.iterrows():\n",
    "    # Get the file paths from the corresponding columns\n",
    "    hour_file_path = row[f\"{data_year}_1h_File_Path\"]\n",
    "    min_30_file_path = row[f\"{data_year}_30min_File_Path\"]\n",
    "    min_15_file_path = row[f\"{data_year}_15min_File_Path\"]\n",
    "    \n",
    "    # Process each file path if it exists\n",
    "    for file_path in [hour_file_path, min_30_file_path, min_15_file_path]:\n",
    "        # Check if the path exists and is not NaN\n",
    "        if isinstance(file_path, str) and os.path.exists(file_path):\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Apply the function to create the Dispa_SET_Time_Step column\n",
    "            df['Dispa_SET_Time_Step'] = df.apply(create_Dispa_SET_Time_Step, axis=1)\n",
    "            \n",
    "            # Save the modified DataFrame back to the CSV file\n",
    "            df.to_csv(file_path, index=False)\n",
    "            \n",
    "            print(f\"CSV file updated successfully: {file_path}\")\n",
    "        else:\n",
    "            print(f\"No valid path specified in row {index + 1}. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a2395-5013-4cd0-8bac-4fdb1521301a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Erasing the unnecesary columns and ordering.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc54003f-4aba-4ff1-a363-204904d2f469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2678497721.py:6: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_csv = pd.read_csv(csv_file)\n",
      "/tmp/ipykernel_69186/2678497721.py:6: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_csv = pd.read_csv(csv_file)\n",
      "/tmp/ipykernel_69186/2678497721.py:6: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_csv = pd.read_csv(csv_file)\n",
      "/tmp/ipykernel_69186/2678497721.py:6: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_csv = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "5     None\n",
       "6     None\n",
       "7     None\n",
       "8     None\n",
       "9     None\n",
       "10    None\n",
       "11    None\n",
       "12    None\n",
       "13    None\n",
       "14    None\n",
       "15    None\n",
       "16    None\n",
       "17    None\n",
       "18    None\n",
       "19    None\n",
       "20    None\n",
       "21    None\n",
       "22    None\n",
       "23    None\n",
       "24    None\n",
       "25    None\n",
       "26    None\n",
       "27    None\n",
       "28    None\n",
       "29    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the function to process each CSV file\n",
    "def process_csv_file(row, time_step_column):\n",
    "    csv_file = row[time_step_column]\n",
    "    if pd.notnull(csv_file) and os.path.exists(csv_file):\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df_csv = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Drop specified columns: Year, Month, Day, Hour, Minute, MTU\n",
    "        columns_to_drop = ['Year', 'Month', 'Day', 'Hour', 'Minute', 'MTU']\n",
    "        df_csv = df_csv.drop(columns=columns_to_drop, errors='ignore')\n",
    "        \n",
    "        # Move the column 'Dispa_SET_Time_Step' to the first position\n",
    "        if 'Dispa_SET_Time_Step' in df_csv.columns:\n",
    "            columns = list(df_csv.columns)\n",
    "            columns.remove('Dispa_SET_Time_Step')\n",
    "            df_csv = df_csv[['Dispa_SET_Time_Step'] + columns]\n",
    "        \n",
    "        # Save the changes back to the CSV file\n",
    "        df_csv.to_csv(csv_file, index=False)\n",
    "        \n",
    "# Define the path to the CSV file containing the file paths\n",
    "#standard_time_data_file_path = \"/home/ray/Dispa-SET_Unleash/RawData/AvailabiltyFactors/Standard_Time_Data.csv\"\n",
    "\n",
    "# Read the CSV file containing the paths\n",
    "df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Convert data_year to a string\n",
    "data_year = str(data_year)\n",
    "\n",
    "# Define the column names for the file paths\n",
    "hour_file_column = data_year + '_1h_File_Path'\n",
    "thirty_min_file_column = data_year + '_30min_File_Path'\n",
    "fifteen_min_file_column = data_year + '_15min_File_Path'\n",
    "\n",
    "# Process the one-hour file\n",
    "df.apply(lambda row: process_csv_file(row, hour_file_column), axis=1)\n",
    "\n",
    "# Process the thirty-minute file\n",
    "df.apply(lambda row: process_csv_file(row, thirty_min_file_column), axis=1)\n",
    "\n",
    "# Process the fifteen-minute file\n",
    "df.apply(lambda row: process_csv_file(row, fifteen_min_file_column), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3980be0-4e8b-49af-a33e-c59734b809d8",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 17px; font-family: TimesNewRoman; color:skyblue\">\n",
    "7. Reservoirs Level Files\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 16px; font-family: TimesNewRoman; color:skyblue\">\n",
    "7.1. Reservoirs Level Clean Files Creation\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Creating all the clean csv files where the final data of the reservoir levels have to be gathered.\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "The next three cells are use to create the content folders (1h, 30 min and/or 15min) and the cleaned csv files according the time step provided by the web source (ENTSO E).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95ef5d14-a432-4243-93ef-6659f04daea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/15min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/30min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/30min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/15min/2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2296304554.py:25: DtypeWarning: Columns (27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(source_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/30min/2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2296304554.py:25: DtypeWarning: Columns (27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(source_file)\n",
      "/tmp/ipykernel_69186/2296304554.py:25: DtypeWarning: Columns (27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(source_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/15min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/30min/2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/2296304554.py:25: DtypeWarning: Columns (27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(source_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/15min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/30min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/15min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/30min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/30min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/15min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/30min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/15min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/30min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/15min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/30min/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/1h/2023.csv\n",
      "Copied and processed data to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/30min/2023.csv\n"
     ]
    }
   ],
   "source": [
    "def process_csv_files(reference_data_file_path, data_year):\n",
    "    \"\"\"Copies, renames, and processes CSV files.\n",
    "\n",
    "    Args:\n",
    "        reference_data_file_path (str): Path to the reference data CSV file.\n",
    "        data_year (str): The year for the target CSV files.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        time_step_folder = row['Time_Step_Reference_Zone_Folder_Path']\n",
    "        zone_folder = row['Zone_Folder_Path']\n",
    "\n",
    "        for time_interval in ['1h', '15min', '30min']:\n",
    "            source_file = os.path.join(time_step_folder, f\"{data_year}_1_{time_interval}.csv\")\n",
    "            destination_folder = os.path.join(zone_folder, time_interval)\n",
    "            old_destination_file = os.path.join(destination_folder, f\"{data_year}_1_{time_interval}.csv\")\n",
    "            new_destination_file = os.path.join(destination_folder, f\"{data_year}.csv\")\n",
    "\n",
    "            if not os.path.exists(destination_folder):\n",
    "                os.makedirs(destination_folder)\n",
    "\n",
    "            if os.path.exists(source_file):\n",
    "                data = pd.read_csv(source_file)\n",
    "                first_column = data.iloc[:, 0]\n",
    "                first_column = first_column.to_frame(name='Value')\n",
    "                first_column['HPHS'] = 0\n",
    "                first_column['HDAM'] = 0\n",
    "\n",
    "                if os.path.exists(old_destination_file):\n",
    "                    os.rename(old_destination_file, new_destination_file)\n",
    "                    print(f\"Renamed file: {old_destination_file} to {new_destination_file}\")\n",
    "\n",
    "                first_column.to_csv(new_destination_file, index=False, mode='a', header=not os.path.exists(new_destination_file))\n",
    "                print(f\"Copied and processed data to {new_destination_file}\")\n",
    "\n",
    "process_csv_files(reference_data_file_path, data_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e5944-cf5e-4b3a-9737-9369af0172c7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Updating the reference_data file with the path to the clean files according the time step\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5817226a-0593-4b43-a0dd-01115a4e2e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/15min/2023_1_15min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/30min/2023_1_30min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/30min/2023_1_30min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/15min/2023_1_15min.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3298507601.py:24: DtypeWarning: Columns (27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(source_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/30min/2023_1_30min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/1h/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3298507601.py:24: DtypeWarning: Columns (27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(source_file)\n",
      "/tmp/ipykernel_69186/3298507601.py:24: DtypeWarning: Columns (27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(source_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/15min/2023_1_15min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/30min/2023_1_30min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/1h/2023_1_1h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/3298507601.py:24: DtypeWarning: Columns (27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(source_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/15min/2023_1_15min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/30min/2023_1_30min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/15min/2023_1_15min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/30min/2023_1_30min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/30min/2023_1_30min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/15min/2023_1_15min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/30min/2023_1_30min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/15min/2023_1_15min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/30min/2023_1_30min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/15min/2023_1_15min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/30min/2023_1_30min.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/1h/2023_1_1h.csv\n",
      "Copied first column and added HPHS, HDAM to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/30min/2023_1_30min.csv\n"
     ]
    }
   ],
   "source": [
    "def copy_first_column_and_add_columns(reference_data_file_path, data_year):\n",
    "    \"\"\"Copies the first column of CSV files to subfolders and adds new columns.\n",
    "\n",
    "    Args:\n",
    "        reference_data_file_path (str): Path to the reference data CSV file.\n",
    "        data_year (str): The year for the target CSV files.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        time_step_folder = row['Time_Step_Reference_Zone_Folder_Path']\n",
    "        zone_folder = row['Zone_Folder_Path']\n",
    "\n",
    "        for time_interval in ['1h', '15min', '30min']:\n",
    "            source_file = os.path.join(time_step_folder, f\"{data_year}_1_{time_interval}.csv\")\n",
    "            destination_folder = os.path.join(zone_folder, time_interval)\n",
    "            destination_file = os.path.join(destination_folder, f\"{data_year}_1_{time_interval}.csv\")\n",
    "\n",
    "            if not os.path.exists(destination_folder):\n",
    "                os.makedirs(destination_folder)\n",
    "\n",
    "            if os.path.exists(source_file):\n",
    "                data = pd.read_csv(source_file)\n",
    "                first_column = data.iloc[:, 0]\n",
    "                first_column = first_column.to_frame(name='Value')\n",
    "                first_column['HPHS'] = 0  # Add HPHS column with initial values\n",
    "                first_column['HDAM'] = 0  # Add HDAM column with initial values\n",
    "                first_column.to_csv(destination_file, index=False)\n",
    "                print(f\"Copied first column and added HPHS, HDAM to {destination_file}\")\n",
    "\n",
    "\n",
    "copy_first_column_and_add_columns(reference_data_file_path, data_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a66affc7-ee79-42b2-b8cd-a36678761438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/1h'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/30min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/1h'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/1h'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/30min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/1h'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/30min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/1h'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/30min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/1h'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/30min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/1h'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/1h'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/30min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/1h'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/30min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/1h'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/30min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/1h'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/15min'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/1h'.\n",
      "CSV file '2023.csv' found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/30min'.\n",
      "CSV file '2023.csv' not found in '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/15min'.\n",
      "CSV file updated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1579858687.py:20: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/1h/2023.csv' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, subfolder] = csv_file_path\n",
      "/tmp/ipykernel_69186/1579858687.py:20: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/30min/2023.csv' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, subfolder] = csv_file_path\n",
      "/tmp/ipykernel_69186/1579858687.py:20: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/15min/2023.csv' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, subfolder] = csv_file_path\n"
     ]
    }
   ],
   "source": [
    "# Read the reference data CSV file\n",
    "df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    zone_folder_path = row['Zone_Folder_Path']\n",
    "    \n",
    "    # Check if the zone folder path exists\n",
    "    if os.path.exists(zone_folder_path):\n",
    "        # Iterate over the required subfolders\n",
    "        for subfolder in ['1h', '30min', '15min']:\n",
    "            subfolder_path = os.path.join(zone_folder_path, subfolder)\n",
    "            \n",
    "            # Check if the subfolder exists\n",
    "            if os.path.exists(subfolder_path):\n",
    "                # Check if the CSV file for the data year exists in the subfolder\n",
    "                csv_file_path = os.path.join(subfolder_path, f\"{data_year}.csv\")\n",
    "                if os.path.exists(csv_file_path):\n",
    "                    # Write the CSV file path to the corresponding column in the DataFrame\n",
    "                    df.at[index, subfolder] = csv_file_path\n",
    "                    print(f\"CSV file '{data_year}.csv' found in '{subfolder_path}'.\")\n",
    "                else:\n",
    "                    print(f\"CSV file '{data_year}.csv' not found in '{subfolder_path}'.\")\n",
    "            else:\n",
    "                print(f\"Subfolder '{subfolder}' does not exist in '{zone_folder_path}'.\")\n",
    "    else:\n",
    "        print(f\"Zone folder path '{zone_folder_path}' does not exist.\")\n",
    "\n",
    "# Save the updated DataFrame to the reference data CSV file\n",
    "df.to_csv(reference_data_file_path, index=False)\n",
    "print(\"CSV file updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0f620-afdf-4f4c-afad-ff5f2806b4f3",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Eransing all the second and third column content excepting the headers and changin the first column header by 'Dispa-SET_Date\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80d2b210-5401-4d40-909c-d3f34b020702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/30min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/15min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/1h/2023.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/30min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/30min/2023.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/15min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/30min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/15min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/30min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/15min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/30min/2023.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/15min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/30min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/30min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/15min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/30min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/15min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/1h/2023.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/1h/2023.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/30min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/15min/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/1h/2023.csv'.\n",
      "Values erased and first column renamed in CSV file '/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/30min/2023.csv'.\n",
      "Process completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n",
      "/tmp/ipykernel_69186/1195302579.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_csv.iloc[:, 1:3] = ''\n"
     ]
    }
   ],
   "source": [
    "def modify_csv_files(reference_data_file_path):\n",
    "    \"\"\"Modifies CSV files by erasing values and renaming the first column.\n",
    "\n",
    "    Args:\n",
    "        reference_data_file_path (str): Path to the reference data CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        for column in ['1h', '30min', '15min']:\n",
    "            csv_file_path = row[column]\n",
    "\n",
    "            if pd.notna(csv_file_path):\n",
    "                df_csv = pd.read_csv(csv_file_path)\n",
    "                df_csv.iloc[:, 1:3] = ''\n",
    "                df_csv.columns = ['Dispa-SET_Date'] + list(df_csv.columns[1:])\n",
    "                df_csv.to_csv(csv_file_path, index=False)\n",
    "                print(f\"Values erased and first column renamed in CSV file '{csv_file_path}'.\")\n",
    "\n",
    "    print(\"Process completed successfully.\")\n",
    "\n",
    "modify_csv_files(reference_data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2b7b16-e42d-4d95-9b6a-7062278af3ac",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 17px; font-family: TimesNewRoman; color:skyblue\">\n",
    "7.2. Reservoirs Level Clean Files Interpolation\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Completing the time data to the clean Reservoirs Level files.\n",
    "<br>\n",
    "For interpolation purposes it is needed to add new dates from the next year to the corresponding Reservoirs Level Clean files.\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Additionally is needed remove duplicated dates if there are any.\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Completing the dates to interpolation purposes.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd86b8d7-e53f-456f-ba5c-0ebfe2d090b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/1h/2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/1h/2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/1h/2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/1h/2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/1h/2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/1h/2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/1h/2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/1h/2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/1h/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/1h/2023.csv\n",
      "Overall processing finished.\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/30min/2023.csv\n",
      "Invalid file path for 30min in row 1: NaN\n",
      "Invalid file path for 30min in row 2: NaN\n",
      "Invalid file path for 30min in row 3: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/30min/2023.csv\n",
      "Invalid file path for 30min in row 5: NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
      "/tmp/ipykernel_69186/121062958.py:37: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/30min/2023.csv\n",
      "Invalid file path for 30min in row 7: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/30min/2023.csv\n",
      "Invalid file path for 30min in row 9: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/30min/2023.csv\n",
      "Invalid file path for 30min in row 11: NaN\n",
      "Invalid file path for 30min in row 12: NaN\n",
      "Invalid file path for 30min in row 13: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/30min/2023.csv\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/30min/2023.csv\n",
      "Invalid file path for 30min in row 16: NaN\n",
      "Invalid file path for 30min in row 17: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/30min/2023.csv\n",
      "Invalid file path for 30min in row 19: NaN\n",
      "Invalid file path for 30min in row 20: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/30min/2023.csv\n",
      "Invalid file path for 30min in row 22: NaN\n",
      "Invalid file path for 30min in row 23: NaN\n",
      "Invalid file path for 30min in row 24: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/30min/2023.csv\n",
      "Invalid file path for 30min in row 26: NaN\n",
      "Invalid file path for 30min in row 27: NaN\n",
      "Invalid file path for 30min in row 28: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/30min/2023.csv\n",
      "Overall processing finished.\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/15min/2023.csv\n",
      "Invalid file path for 15min in row 1: NaN\n",
      "Invalid file path for 15min in row 2: NaN\n",
      "Invalid file path for 15min in row 3: NaN\n",
      "Invalid file path for 15min in row 4: NaN\n",
      "Invalid file path for 15min in row 5: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/15min/2023.csv\n",
      "Invalid file path for 15min in row 7: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/15min/2023.csv\n",
      "Invalid file path for 15min in row 9: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/15min/2023.csv\n",
      "Invalid file path for 15min in row 11: NaN\n",
      "Invalid file path for 15min in row 12: NaN\n",
      "Invalid file path for 15min in row 13: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/15min/2023.csv\n",
      "Invalid file path for 15min in row 15: NaN\n",
      "Invalid file path for 15min in row 16: NaN\n",
      "Invalid file path for 15min in row 17: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/15min/2023.csv\n",
      "Invalid file path for 15min in row 19: NaN\n",
      "Invalid file path for 15min in row 20: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/15min/2023.csv\n",
      "Invalid file path for 15min in row 22: NaN\n",
      "Invalid file path for 15min in row 23: NaN\n",
      "Invalid file path for 15min in row 24: NaN\n",
      "New rows added successfully to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/15min/2023.csv\n",
      "Invalid file path for 15min in row 26: NaN\n",
      "Invalid file path for 15min in row 27: NaN\n",
      "Invalid file path for 15min in row 28: NaN\n",
      "Invalid file path for 15min in row 29: NaN\n",
      "Overall processing finished.\n"
     ]
    }
   ],
   "source": [
    "def add_new_rows(time_step):\n",
    "    # Define reference data file path\n",
    "    # reference_data_file_path = \"/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Reference_Data.csv\"\n",
    "\n",
    "    # Read the reference data CSV file\n",
    "    df_reference = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df_reference.iterrows():\n",
    "        # Get the file paths from the specified columns\n",
    "        file_path_1 = row[time_step]\n",
    "        file_path_2 = row['Single_Raw_Data_File_Path']\n",
    "\n",
    "        # Check if file_path_1 is not NaN\n",
    "        if isinstance(file_path_1, str):  # Check if file_path_1 is a string\n",
    "            # Read the first column (time) from file_path_1\n",
    "            df1 = pd.read_csv(file_path_1)\n",
    "            last_date_file1 = pd.to_datetime(df1.iloc[-1, 0])\n",
    "\n",
    "            # Read the 'Dispa-SET_Date' column from file_path_2\n",
    "            df2 = pd.read_csv(file_path_2)\n",
    "            last_date_file2 = pd.to_datetime(df2['Dispa-SET_Date'].iloc[-1])\n",
    "\n",
    "            # Check if the last date from file_path_1 is less than the last date from file_path_2\n",
    "            if last_date_file1 < last_date_file2:\n",
    "                # Calculate time steps until reaching the last date from file_path_2\n",
    "                if time_step == '1h':\n",
    "                    freq = '1H'\n",
    "                elif time_step == '30min':\n",
    "                    freq = '30Min'\n",
    "                elif time_step == '15min':\n",
    "                    freq = '15Min'\n",
    "                else:\n",
    "                    print(\"Invalid time step frequency.\")\n",
    "                    return\n",
    "                \n",
    "                time_steps = pd.date_range(start=last_date_file1, end=last_date_file2, freq=freq)\n",
    "\n",
    "                # Create a new DataFrame with time steps, only in the first column\n",
    "                df_new_rows = pd.DataFrame({df1.columns[0]: time_steps[1:]})\n",
    "\n",
    "                # Append the new rows to the first column of file_path_1 DataFrame\n",
    "                df1 = pd.concat([df1, df_new_rows], ignore_index=True)\n",
    "\n",
    "                # Save the updated DataFrame back to the original CSV file\n",
    "                df1.to_csv(file_path_1, index=False)\n",
    "                print(f\"New rows added successfully to {file_path_1}\")\n",
    "            else:\n",
    "                print(f\"No new rows need to be added to {file_path_1}\")\n",
    "        else:\n",
    "            print(f\"Invalid file path for {time_step} in row {index}: NaN\")\n",
    "\n",
    "    print(\"Overall processing finished.\")\n",
    "\n",
    "# Add new rows with 1 hour time step\n",
    "add_new_rows('1h')\n",
    "\n",
    "# Add new rows with 30 minute time step\n",
    "add_new_rows('30min')\n",
    "\n",
    "# Add new rows with 15 minute time step\n",
    "add_new_rows('15min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b89f16-ead3-4ba7-b3bf-6124128cc87e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Erasing duplicated dates.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e615b9eb-1984-4b3d-8e80-a10a708cd782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/1h/2023.csv\n",
      "Duplicates removed successfully from 30min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/30min/2023.csv\n",
      "Duplicates removed successfully from 15min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/15min/2023.csv\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/1h/2023.csv\n",
      "Invalid file path for 30min in row 1: NaN\n",
      "Invalid file path for 15min in row 1: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/1h/2023.csv\n",
      "Invalid file path for 30min in row 2: NaN\n",
      "Invalid file path for 15min in row 2: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/1h/2023.csv\n",
      "Invalid file path for 30min in row 3: NaN\n",
      "Invalid file path for 15min in row 3: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/1h/2023.csv\n",
      "Duplicates removed successfully from 30min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/30min/2023.csv\n",
      "Invalid file path for 15min in row 4: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/1h/2023.csv\n",
      "Invalid file path for 30min in row 5: NaN\n",
      "Invalid file path for 15min in row 5: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/1h/2023.csv\n",
      "Duplicates removed successfully from 30min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/30min/2023.csv\n",
      "Duplicates removed successfully from 15min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/15min/2023.csv\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/1h/2023.csv\n",
      "Invalid file path for 30min in row 7: NaN\n",
      "Invalid file path for 15min in row 7: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/1h/2023.csv\n",
      "Duplicates removed successfully from 30min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/30min/2023.csv\n",
      "Duplicates removed successfully from 15min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/15min/2023.csv\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/1h/2023.csv\n",
      "Invalid file path for 30min in row 9: NaN\n",
      "Invalid file path for 15min in row 9: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/1h/2023.csv\n",
      "Duplicates removed successfully from 30min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/30min/2023.csv\n",
      "Duplicates removed successfully from 15min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/15min/2023.csv\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/1h/2023.csv\n",
      "Invalid file path for 30min in row 11: NaN\n",
      "Invalid file path for 15min in row 11: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/1h/2023.csv\n",
      "Invalid file path for 30min in row 12: NaN\n",
      "Invalid file path for 15min in row 12: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/1h/2023.csv\n",
      "Invalid file path for 30min in row 13: NaN\n",
      "Invalid file path for 15min in row 13: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/1h/2023.csv\n",
      "Duplicates removed successfully from 30min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/30min/2023.csv\n",
      "Duplicates removed successfully from 15min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/15min/2023.csv\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/1h/2023.csv\n",
      "Duplicates removed successfully from 30min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/30min/2023.csv\n",
      "Invalid file path for 15min in row 15: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/1h/2023.csv\n",
      "Invalid file path for 30min in row 16: NaN\n",
      "Invalid file path for 15min in row 16: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/1h/2023.csv\n",
      "Invalid file path for 30min in row 17: NaN\n",
      "Invalid file path for 15min in row 17: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/1h/2023.csv\n",
      "Duplicates removed successfully from 30min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/30min/2023.csv\n",
      "Duplicates removed successfully from 15min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/15min/2023.csv\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/1h/2023.csv\n",
      "Invalid file path for 30min in row 19: NaN\n",
      "Invalid file path for 15min in row 19: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/1h/2023.csv\n",
      "Invalid file path for 30min in row 20: NaN\n",
      "Invalid file path for 15min in row 20: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/1h/2023.csv\n",
      "Duplicates removed successfully from 30min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/30min/2023.csv\n",
      "Duplicates removed successfully from 15min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/15min/2023.csv\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/1h/2023.csv\n",
      "Invalid file path for 30min in row 22: NaN\n",
      "Invalid file path for 15min in row 22: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/1h/2023.csv\n",
      "Invalid file path for 30min in row 23: NaN\n",
      "Invalid file path for 15min in row 23: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/1h/2023.csv\n",
      "Invalid file path for 30min in row 24: NaN\n",
      "Invalid file path for 15min in row 24: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/1h/2023.csv\n",
      "Duplicates removed successfully from 30min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/30min/2023.csv\n",
      "Duplicates removed successfully from 15min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/15min/2023.csv\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/1h/2023.csv\n",
      "Invalid file path for 30min in row 26: NaN\n",
      "Invalid file path for 15min in row 26: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/1h/2023.csv\n",
      "Invalid file path for 30min in row 27: NaN\n",
      "Invalid file path for 15min in row 27: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/1h/2023.csv\n",
      "Invalid file path for 30min in row 28: NaN\n",
      "Invalid file path for 15min in row 28: NaN\n",
      "Duplicates removed successfully from 1h file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/1h/2023.csv\n",
      "Duplicates removed successfully from 30min file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/30min/2023.csv\n",
      "Invalid file path for 15min in row 29: NaN\n",
      "Overall processing finished.\n"
     ]
    }
   ],
   "source": [
    "# Define reference data file path\n",
    "#reference_data_file_path = \"/home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/Reference_Data.csv\"\n",
    "\n",
    "# Read the reference data CSV file\n",
    "df_reference = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_reference.iterrows():\n",
    "    # Get the file paths from the specified columns\n",
    "    file_paths = {'1h': row['1h'], '30min': row['30min'], '15min': row['15min']}\n",
    "\n",
    "    for time_step, file_path in file_paths.items():\n",
    "        # Check if file_path is not NaN and is a string\n",
    "        if isinstance(file_path, str):  \n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Remove rows with duplicated values in the first column\n",
    "            if not df.empty:  # Check if the DataFrame is not empty\n",
    "                df = df.drop_duplicates(subset=df.columns[0], keep='first')\n",
    "\n",
    "                # Save the updated DataFrame back to the original CSV file\n",
    "                df.to_csv(file_path, index=False)\n",
    "\n",
    "                print(f\"Duplicates removed successfully from {time_step} file: {file_path}\")\n",
    "            else:\n",
    "                print(f\"Empty DataFrame for {time_step} file: {file_path}. No duplicates to remove.\")\n",
    "        else:\n",
    "            print(f\"Invalid file path for {time_step} in row {index}: NaN\")\n",
    "\n",
    "print(\"Overall processing finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2bd46-80e8-4595-bd41-de8a12445c5d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Copying the weekly data to the clean csv Reservoirs Level files.\n",
    "<div/>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "For interpolation purposes it is needed copy the data per week to the corresponding date in the clean csv Reservoirs Level files.\n",
    "<div/>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "This is done for all the 30 countries modelled in Dispa-SET and for each corresponding time step as well (1 hou, 30 minutes and 15 minutes)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "facbbeb2-97cb-4557-b218-171a0df67974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/1h/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/30min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/15min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/1h/2023.csv\n",
      "Invalid file paths in row 1: NaN\n",
      "Invalid file paths in row 1: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/1h/2023.csv\n",
      "Invalid file paths in row 2: NaN\n",
      "Invalid file paths in row 2: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/1h/2023.csv\n",
      "Invalid file paths in row 3: NaN\n",
      "Invalid file paths in row 3: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/1h/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/30min/2023.csv\n",
      "Invalid file paths in row 4: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/1h/2023.csv\n",
      "Invalid file paths in row 5: NaN\n",
      "Invalid file paths in row 5: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/1h/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/30min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/15min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/1h/2023.csv\n",
      "Invalid file paths in row 7: NaN\n",
      "Invalid file paths in row 7: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/1h/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/30min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/15min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/1h/2023.csv\n",
      "Invalid file paths in row 9: NaN\n",
      "Invalid file paths in row 9: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/1h/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/30min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/15min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/1h/2023.csv\n",
      "Invalid file paths in row 11: NaN\n",
      "Invalid file paths in row 11: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/1h/2023.csv\n",
      "Invalid file paths in row 12: NaN\n",
      "Invalid file paths in row 12: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/1h/2023.csv\n",
      "Invalid file paths in row 13: NaN\n",
      "Invalid file paths in row 13: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/1h/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/30min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/15min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/1h/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/30min/2023.csv\n",
      "Invalid file paths in row 15: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/1h/2023.csv\n",
      "Invalid file paths in row 16: NaN\n",
      "Invalid file paths in row 16: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/1h/2023.csv\n",
      "Invalid file paths in row 17: NaN\n",
      "Invalid file paths in row 17: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/1h/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/30min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/15min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/1h/2023.csv\n",
      "Invalid file paths in row 19: NaN\n",
      "Invalid file paths in row 19: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/1h/2023.csv\n",
      "Invalid file paths in row 20: NaN\n",
      "Invalid file paths in row 20: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/1h/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/30min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/15min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/1h/2023.csv\n",
      "Invalid file paths in row 22: NaN\n",
      "Invalid file paths in row 22: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/1h/2023.csv\n",
      "Invalid file paths in row 23: NaN\n",
      "Invalid file paths in row 23: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/1h/2023.csv\n",
      "Invalid file paths in row 24: NaN\n",
      "Invalid file paths in row 24: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/1h/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/30min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/15min/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/1h/2023.csv\n",
      "Invalid file paths in row 26: NaN\n",
      "Invalid file paths in row 26: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/1h/2023.csv\n",
      "Invalid file paths in row 27: NaN\n",
      "Invalid file paths in row 27: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/1h/2023.csv\n",
      "Invalid file paths in row 28: NaN\n",
      "Invalid file paths in row 28: NaN\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/1h/2023.csv\n",
      "Values copied successfully from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/2023_1.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/30min/2023.csv\n",
      "Invalid file paths in row 29: NaN\n",
      "Overall processing finished.\n"
     ]
    }
   ],
   "source": [
    "# Read the reference data CSV file\n",
    "df_reference = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_reference.iterrows():\n",
    "    for time_interval in ['1h', '30min', '15min']:\n",
    "        # Get the file paths from the specified columns\n",
    "        file_path_1 = row[time_interval]\n",
    "        file_path_2 = row['Single_Raw_Data_File_Path']\n",
    "\n",
    "        # Check if both file paths are not NaN\n",
    "        if isinstance(file_path_1, str) and isinstance(file_path_2, str):\n",
    "            # Read CSV files\n",
    "            df_1 = pd.read_csv(file_path_1)\n",
    "            df_2 = pd.read_csv(file_path_2)\n",
    "\n",
    "            # Get the data year from the file path\n",
    "            data_year = int(file_path_1.split('/')[-1].split('.')[0])\n",
    "\n",
    "            # Get the column name corresponding to the data year\n",
    "            year_column = str(data_year)\n",
    "\n",
    "            # Iterate over each row in df_2\n",
    "            for _, row_2 in df_2.iterrows():\n",
    "                # Get the value from the 'Dispa-SET_Date' column in df_2\n",
    "                date_value = row_2['Dispa-SET_Date']\n",
    "\n",
    "                # Check if the value exists in the first column of df_1\n",
    "                if date_value in df_1[df_1.columns[0]].values:\n",
    "                    # Get the index where the value is found in df_1\n",
    "                    index_value = df_1.index[df_1[df_1.columns[0]] == date_value][0]\n",
    "                    # Copy corresponding value from df_2 and paste it to the corresponding fields of the second and third columns in df_1\n",
    "                    df_1.at[index_value, df_1.columns[1]] = row_2[year_column]\n",
    "                    df_1.at[index_value, df_1.columns[2]] = row_2[year_column]\n",
    "\n",
    "            # Save the updated DataFrame back to the original CSV file\n",
    "            df_1.to_csv(file_path_1, index=False)\n",
    "            print(f\"Values copied successfully from {file_path_2} to {file_path_1}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Invalid file paths in row {index}: NaN\")\n",
    "\n",
    "print(\"Overall processing finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa466c74-9d3c-4042-b461-bdc490688e9a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Interpolating the clean csv Reservoirs Level fiels.\n",
    "<div/>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "A linear interpolation process is used to get the values needed between each weekly data.\n",
    "<br>\n",
    "This is done for all the 30 countries modelled in Dispa-SET and for each corresponding time step as well (1 hou, 30 minutes and 15 minutes)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb15d610-691f-4975-a5c4-d3c0f37b37c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/30min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/15min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/30min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/30min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/15min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/30min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/15min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/30min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/15min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/30min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/15min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/30min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/30min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/15min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/30min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/15min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/30min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/15min/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/1h/2023.csv\n",
      "Linear interpolation completed for /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/30min/2023.csv\n",
      "Overall processing finished.\n"
     ]
    }
   ],
   "source": [
    "# Read the reference data CSV file\n",
    "df_reference = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Define the columns to be interpolated\n",
    "columns_to_interpolate = ['HPHS', 'HDAM']  # Replace with actual column names\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_reference.iterrows():\n",
    "    # Get the file paths from the specified columns\n",
    "    file_path_1h = row['1h']\n",
    "    file_path_30min = row['30min']\n",
    "    file_path_15min = row['15min']\n",
    "\n",
    "    # Check if any of the file paths are not NaN\n",
    "    if isinstance(file_path_1h, str):\n",
    "        # Read CSV file for 1h\n",
    "        df_1h = pd.read_csv(file_path_1h)\n",
    "        # Perform linear interpolation for 1h columns\n",
    "        df_1h[columns_to_interpolate] = df_1h[columns_to_interpolate].interpolate(method='linear')\n",
    "        # Save the interpolated DataFrame back to the CSV file\n",
    "        df_1h.to_csv(file_path_1h, index=False)\n",
    "        print(f\"Linear interpolation completed for {file_path_1h}\")\n",
    "\n",
    "    if isinstance(file_path_30min, str):\n",
    "        # Read CSV file for 30min\n",
    "        df_30min = pd.read_csv(file_path_30min)\n",
    "        # Perform linear interpolation for 30min columns\n",
    "        df_30min[columns_to_interpolate] = df_30min[columns_to_interpolate].interpolate(method='linear')\n",
    "        # Save the interpolated DataFrame back to the CSV file\n",
    "        df_30min.to_csv(file_path_30min, index=False)\n",
    "        print(f\"Linear interpolation completed for {file_path_30min}\")\n",
    "\n",
    "    if isinstance(file_path_15min, str):\n",
    "        # Read CSV file for 15min\n",
    "        df_15min = pd.read_csv(file_path_15min)\n",
    "        # Perform linear interpolation for 15min columns\n",
    "        df_15min[columns_to_interpolate] = df_15min[columns_to_interpolate].interpolate(method='linear')\n",
    "        # Save the interpolated DataFrame back to the CSV file\n",
    "        df_15min.to_csv(file_path_15min, index=False)\n",
    "        print(f\"Linear interpolation completed for {file_path_15min}\")\n",
    "\n",
    "print(\"Overall processing finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b57f1-e36c-4b28-a62b-5cd763fe32dd",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Getting the final Reservoirs Level file.\n",
    "<div/>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "A process of dates filtering is done, since just the analized year (specified in the data_year variable) is required.\n",
    "<br>\n",
    "This is done for all the 30 countries modelled in Dispa-SET and for each corresponding time step as well (1 hou, 30 minutes and 15 minutes)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "196147f8-bee7-4862-96fb-96294b30b286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/30min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/15min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/30min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/30min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/15min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/30min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/15min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/30min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/15min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/30min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/15min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/30min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/30min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/15min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/30min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/15min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/30min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/15min/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/1h/2023.csv\n",
      "Rows not belonging to 2023 have been removed from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/30min/2023.csv\n",
      "Overall processing finished.\n"
     ]
    }
   ],
   "source": [
    "# Define a function to process each file\n",
    "def process_file(file_path):\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"No file found at {file_path}\")\n",
    "        return None\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert the first column to datetime\n",
    "    df['Dispa-SET_Date'] = pd.to_datetime(df['Dispa-SET_Date'])\n",
    "\n",
    "    # Extract the year from the date values\n",
    "    df['Year'] = df['Dispa-SET_Date'].dt.year\n",
    "\n",
    "    # Filter out rows that belong to the specified year\n",
    "    data_year = int(os.path.basename(file_path).split('.')[0])\n",
    "    df_filtered = df[df['Year'] == data_year].copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "    # Drop the 'Year' column\n",
    "    df_filtered.drop(columns=['Year'], inplace=True)\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# Read the reference data CSV file\n",
    "df_reference = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_reference.iterrows():\n",
    "    # Get the file paths from the specified columns\n",
    "    file_path_1h = row['1h']\n",
    "    file_path_30min = row['30min']\n",
    "    file_path_15min = row['15min']\n",
    "\n",
    "    # Process the file path for '1h'\n",
    "    if isinstance(file_path_1h, str):\n",
    "        df_filtered_1h = process_file(file_path_1h)\n",
    "        if df_filtered_1h is not None:\n",
    "            df_filtered_1h.to_csv(file_path_1h, index=False)\n",
    "            print(f\"Rows not belonging to {data_year} have been removed from {file_path_1h}\")\n",
    "        else:\n",
    "            print(f\"No file found for '1h' at index {index}\")\n",
    "\n",
    "    # Process the file path for '30min'\n",
    "    if isinstance(file_path_30min, str):\n",
    "        df_filtered_30min = process_file(file_path_30min)\n",
    "        if df_filtered_30min is not None:\n",
    "            df_filtered_30min.to_csv(file_path_30min, index=False)\n",
    "            print(f\"Rows not belonging to {data_year} have been removed from {file_path_30min}\")\n",
    "        else:\n",
    "            print(f\"No file found for '30min' at index {index}\")\n",
    "\n",
    "    # Process the file path for '15min'\n",
    "    if isinstance(file_path_15min, str):\n",
    "        df_filtered_15min = process_file(file_path_15min)\n",
    "        if df_filtered_15min is not None:\n",
    "            df_filtered_15min.to_csv(file_path_15min, index=False)\n",
    "            print(f\"Rows not belonging to {data_year} have been removed from {file_path_15min}\")\n",
    "        else:\n",
    "            print(f\"No file found for '15min' at index {index}\")\n",
    "\n",
    "print(\"Overall processing finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d11924-4298-49a3-95d3-8fbd3f000028",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Updating the Dispa-SET time column.\n",
    "<div/>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Since this column header does not have to have any value, the same is erased.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b08bb3f-34a9-44b2-9129-cbce0f4d4099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/30min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/15min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/30min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/30min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/15min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/30min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/15min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/30min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/15min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/30min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/15min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/30min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/30min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/15min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/30min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/15min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/30min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/15min/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/1h/2023.csv\n",
      "Renamed first column in /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/30min/2023.csv\n"
     ]
    }
   ],
   "source": [
    "def rename_column(reference_data_file_path):\n",
    "    \"\"\"Renames the first column of specified CSV files.\n",
    "\n",
    "    Args:\n",
    "        reference_data_file_path (str): Path to the reference data CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    df_reference = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "    for index, row in df_reference.iterrows():\n",
    "        for time_interval in ['1h', '30min', '15min']:\n",
    "            file_path = row[time_interval]\n",
    "\n",
    "            if pd.notnull(file_path):  # Check if file path is not null\n",
    "                df = pd.read_csv(file_path)\n",
    "                df.columns = ['', df.columns[1], df.columns[2]]\n",
    "                df.to_csv(file_path, index=False)\n",
    "                print(f\"Renamed first column in {file_path}\")\n",
    "\n",
    "rename_column(reference_data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b33822-5630-4ec4-802a-b97cc83e0e11",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Erasing empty subfolders.\n",
    "<div/>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "For the next stept the already processed data is going to be copied to the Dispa-SET data base.\n",
    "<br>\n",
    "Empty folder are not necesary to be copied, so they are erased.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5a021d2-aadb-4500-b155-01f535e76d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/30min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/15min\n",
      "Removed empty subfolder: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/15min\n"
     ]
    }
   ],
   "source": [
    "def remove_empty_subfolders(reference_data_file_path):\n",
    "    \"\"\"Removes empty subfolders within specified folders.\n",
    "\n",
    "    Args:\n",
    "        reference_data_file_path (str): Path to the reference data CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    df_reference = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "    for index, row in df_reference.iterrows():\n",
    "        zone_folder = row['Zone_Folder_Path']\n",
    "\n",
    "        for time_interval in ['1h', '30min', '15min']:\n",
    "            subfolder_path = os.path.join(zone_folder, time_interval)\n",
    "\n",
    "            if os.path.exists(subfolder_path) and not os.listdir(subfolder_path):\n",
    "                os.rmdir(subfolder_path)\n",
    "                print(f\"Removed empty subfolder: {subfolder_path}\")\n",
    "\n",
    "remove_empty_subfolders(reference_data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147f1172-ac68-4640-90f9-52dc45155ab6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 17px; font-family: TimesNewRoman; color:skyblue\">\n",
    "8. Reservoir Level Files\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "The already processed Reservoirs Level Time Series are copied to the Dispa-SET data base.\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 2.0em; font-weight: unbold; font-size: 13px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Defining the neede directory paths.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e3dc8af-0477-4dd2-9579-7ffd233fe79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reservoir_level_dispaset_folder_path: /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/\n"
     ]
    }
   ],
   "source": [
    "# Additional string to be appended\n",
    "additional_path_4 = \"/Database/HydroData/ReservoirLevel/\"\n",
    "\n",
    "# Construct the reservoir_level_dispa-set_folder_path variable\n",
    "reservoir_level_dispaset_folder_path = dispaSET_unleash_folder_path + additional_path_4\n",
    "\n",
    "print(\"reservoir_level_dispaset_folder_path:\", reservoir_level_dispaset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ca578-3ad5-49cd-8550-1793532ab58d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Copying the final reservoir level files.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "397a3acd-a061-4820-b143-5f895d360837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/AT/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/15min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/AT/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/30min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/AT/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/BE/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/BG/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/CH/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/CY/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/30min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/CY/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/CZ/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/DE/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/15min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/DE/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/30min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/DE/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/DK/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/EE/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/15min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/EE/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/30min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/EE/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/EL/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/ES/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/15min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/ES/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/30min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/ES/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/FI/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/FR/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/HR/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/HU/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/15min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/HU/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/30min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/HU/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/IE/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/30min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/IE/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/IT/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/LT/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/LU/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/15min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/LU/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/30min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/LU/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/LV/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/MT/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/NL/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/15min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/NL/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/30min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/NL/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/NO/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/PL/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/PT/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/RO/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/15min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/RO/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/30min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/RO/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/SE/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/SI/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/SK/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/15min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/1h/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/UK/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/30min/2023.csv to /home/ray/Dispa-SET_Unleash/Database/HydroData/ReservoirLevel/UK/30min/2023.csv\n",
      "All files processed.\n"
     ]
    }
   ],
   "source": [
    "# Read the reference data CSV file\n",
    "df_reference = pd.read_csv(reference_data_file_path)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_reference.iterrows():\n",
    "    zone_folder_path = row['Zone_Folder_Path']\n",
    "\n",
    "    # Iterate over each time resolution subfolder ('1h', '15min', '30min')\n",
    "    for time_resolution in ['1h', '15min', '30min']:\n",
    "        source_file_path = os.path.join(zone_folder_path, time_resolution, f\"{data_year}.csv\")\n",
    "        \n",
    "        # Check if the source file exists\n",
    "        if os.path.isfile(source_file_path):\n",
    "            dispaSET_code = os.path.basename(zone_folder_path)  # Extract the folder name, assumed to be the Dispa-SET code\n",
    "            destination_folder = os.path.join(reservoir_level_dispaset_folder_path, dispaSET_code, time_resolution)\n",
    "\n",
    "            # Create the destination directory if it doesn't exist\n",
    "            os.makedirs(destination_folder, exist_ok=True)\n",
    "            \n",
    "            # Define the destination file path\n",
    "            destination_file_path = os.path.join(destination_folder, f\"{data_year}.csv\")\n",
    "            \n",
    "            # Copy the file\n",
    "            shutil.copy2(source_file_path, destination_file_path)\n",
    "            print(f\"Copied {source_file_path} to {destination_file_path}\")\n",
    "        else:\n",
    "            print(f\"File not found: {source_file_path}\")\n",
    "\n",
    "print(\"All files processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e6928-da68-4298-a0fe-fc9e76778b13",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 17px; font-family: TimesNewRoman; color:skyblue\">\n",
    "9. Scaled Inflows Data\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "The already processed Reservoirs Level Time Series are needed to be used to process the Scaled Inflows time series.\n",
    "<br>\n",
    "The next cells are use to get the apropiate data and then copy it to the sacled inflow directory\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Defining the needed directory paths.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eeb1aeb3-46b5-490a-9fe9-8b5426be988a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level_folder_path: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/\n"
     ]
    }
   ],
   "source": [
    "additional_path_6 = \"/RawData/HydroData/ScaledInflows/Levels/\"\n",
    "\n",
    "# Construct the_level_folder_path variable\n",
    "level_folder_path = dispaSET_unleash_folder_path + additional_path_6\n",
    "\n",
    "print(\"level_folder_path:\", level_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f91852-f260-405f-b96b-015d2bc69aba",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Copyin the needed time series to the level folder in the scaled inflows directory.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d2c4fb7-e04d-4c95-9035-bf3cb7e04cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/AT/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/30min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/AT/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/AT/15min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/AT/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BE/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/BE/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/BG/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/BG/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CH/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/CH/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/CY/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CY/30min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/CY/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/CZ/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/CZ/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/DE/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/30min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/DE/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DE/15min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/DE/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/DK/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/DK/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/EE/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/30min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/EE/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EE/15min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/EE/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/EL/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/EL/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/ES/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/30min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/ES/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/ES/15min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/ES/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FI/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/FI/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/FR/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/FR/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HR/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/HR/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/HU/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/30min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/HU/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/HU/15min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/HU/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/IE/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IE/30min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/IE/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/IT/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/IT/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LT/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/LT/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/LU/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/30min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/LU/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LU/15min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/LU/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/LV/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/LV/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/MT/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/MT/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/NL/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/30min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/NL/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NL/15min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/NL/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/NO/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/NO/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PL/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/PL/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/PT/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/PT/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/RO/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/30min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/RO/30min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/RO/15min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/RO/15min/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SE/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/SE/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SI/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/SI/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/SK/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/SK/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/1h/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/UK/1h/2023.csv\n",
      "Copied /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel/UK/30min/2023.csv to /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/UK/30min/2023.csv\n"
     ]
    }
   ],
   "source": [
    "def copy_csv_files(dispaSET_codes, reservoir_level_folder_path, level_folder_path, data_year):\n",
    "  \"\"\"\n",
    "  Copies CSV files from subfolders to a new structure.\n",
    "\n",
    "  Args:\n",
    "    dispaSET_codes: A list of dispaSET codes.\n",
    "    reservoir_level_folder_path: The path to the source folder.\n",
    "    level_folder_path: The path to the destination folder.\n",
    "    data_year: The year for the CSV files.\n",
    "  \"\"\"\n",
    "\n",
    "  for code in dispaSET_codes:\n",
    "    source_code_folder = os.path.join(reservoir_level_folder_path, code)\n",
    "    destination_code_folder = os.path.join(level_folder_path, code)\n",
    "\n",
    "    if not os.path.exists(destination_code_folder):\n",
    "      os.makedirs(destination_code_folder)\n",
    "\n",
    "    for subfolder in ['1h', '30min', '15min']:\n",
    "      source_file = os.path.join(source_code_folder, subfolder, f\"{data_year}.csv\")\n",
    "      destination_file = os.path.join(destination_code_folder, subfolder, f\"{data_year}.csv\")\n",
    "\n",
    "      if os.path.exists(source_file):\n",
    "        os.makedirs(os.path.dirname(destination_file), exist_ok=True)\n",
    "        shutil.copy2(source_file, destination_file)\n",
    "        print(f\"Copied {source_file} to {destination_file}\")\n",
    "\n",
    "copy_csv_files(dispaSET_codes, reservoir_level_folder_path, level_folder_path, data_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fcf136-e202-47a2-991b-102df6529d74",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 0.0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Adding two new columns to get the value of the levels in MW.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7c3e631-fe65-4cf6-b3c2-4ec10c2972f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/AT/1h/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/AT/30min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/AT/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/BE/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/BE/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/BE/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/BG/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/BG/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/BG/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/CH/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/CH/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/CH/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/CY/1h/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/CY/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/CY/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/CZ/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/CZ/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/CZ/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/DE/1h/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/DE/30min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/DE/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/DK/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/DK/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/DK/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/EE/1h/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/EE/30min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/EE/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/EL/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/EL/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/EL/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/ES/1h/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/ES/30min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/ES/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/FI/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/FI/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/FI/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/FR/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/FR/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/FR/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/HR/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/HR/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/HR/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/HU/1h/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/HU/30min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/HU/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/IE/1h/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/IE/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/IE/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/IT/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/IT/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/IT/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/LT/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/LT/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/LT/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/LU/1h/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/LU/30min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/LU/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/LV/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/LV/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/LV/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/MT/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/MT/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/MT/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/NL/1h/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/NL/30min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/NL/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/NO/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/NO/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/NO/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/PL/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/PL/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/PL/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/PT/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/PT/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/PT/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/RO/1h/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/RO/30min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/RO/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/SE/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/SE/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/SE/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/SI/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/SI/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/SI/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/SK/1h/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/SK/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/SK/15min/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/UK/1h/2023.csv\n",
      "Processed file: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/UK/30min/2023.csv\n",
      "File not found: /home/ray/Dispa-SET_Unleash/RawData/HydroData/ScaledInflows/Levels/UK/15min/2023.csv\n"
     ]
    }
   ],
   "source": [
    "def multiply_columns(data_year, dispaSET_codes, level_folder_path, reference_data_file_path):\n",
    "    \"\"\"Multiply the HPHS and HDAM columns in the CSV files by the corresponding Maximum_Level value.\n",
    "       Save the results in new columns HPHS_MW and HDAM_MW.\"\"\"\n",
    "    \n",
    "    # Read the reference data file\n",
    "    df_reference = pd.read_csv(reference_data_file_path)\n",
    "    \n",
    "    for dispa_code in dispaSET_codes:\n",
    "        # Find the corresponding Maximum_Level for the current dispaSET_code\n",
    "        max_level = df_reference.loc[df_reference['Dispa-SET_Code'] == dispa_code, 'Maximum_Level'].values[0]\n",
    "        \n",
    "        # Construct the path to the folder for this dispaSET_code\n",
    "        dispa_folder_path = os.path.join(level_folder_path, dispa_code)\n",
    "        \n",
    "        # List of subfolders to check (1h, 30min, 15min)\n",
    "        subfolders = ['1h', '30min', '15min']\n",
    "        \n",
    "        for subfolder in subfolders:\n",
    "            subfolder_path = os.path.join(dispa_folder_path, subfolder)\n",
    "            csv_file_path = os.path.join(subfolder_path, f\"{data_year}.csv\")\n",
    "            \n",
    "            # Check if the CSV file exists\n",
    "            if os.path.exists(csv_file_path):\n",
    "                # Read the CSV file\n",
    "                df = pd.read_csv(csv_file_path)\n",
    "                \n",
    "                # Multiply HPHS and HDAM columns by max_level and create new columns\n",
    "                df['HPHS_MW'] = df['HPHS'] * max_level\n",
    "                df['HDAM_MW'] = df['HDAM'] * max_level\n",
    "                \n",
    "                # Save the updated CSV file with the new columns\n",
    "                df.to_csv(csv_file_path, index=False)\n",
    "                \n",
    "                # Print a message indicating that the file was processed\n",
    "                print(f\"Processed file: {csv_file_path}\")\n",
    "            else:\n",
    "                print(f\"File not found: {csv_file_path}\")\n",
    "\n",
    "multiply_columns(data_year, dispaSET_codes, level_folder_path, reference_data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963e134-542b-4950-b64d-441f819dc777",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; margin-left: 3.0em; font-weight: bold; font-size: 17px; font-family: TimesNewRoman; color:skyblue\">\n",
    "9. Reservoir Level Folder Back Up\n",
    "</div>\n",
    "<div style=\"text-align: justify; margin-left: 0em; font-weight: unbold; font-size: 14px; font-family: TimesNewRoman; color:skyblue\">\n",
    "Once all the formating process was done the Reservoir Level Folder is restored to its defoult state.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9745d122-bf67-4e55-9334-0b23a7577f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory restored to original state from /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel_backup/\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(reservoir_level_folder_path):\n",
    "    shutil.rmtree(reservoir_level_folder_path)  # Remove the current directory\n",
    "shutil.copytree(backup_folder_path, reservoir_level_folder_path)\n",
    "\n",
    "print(f\"Directory restored to original state from {backup_folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3fb46596-d6e8-4ec6-950d-0ef0638ab8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup folder /home/ray/Dispa-SET_Unleash/RawData/HydroData/ReservoirLevel_backup/ deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(backup_folder_path)\n",
    "print(f\"Backup folder {backup_folder_path} deleted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30c7a7-f44d-45f6-9a08-ffb3e848d7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
