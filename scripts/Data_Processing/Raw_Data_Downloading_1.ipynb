{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f30da9-960c-4e04-b4ee-8ff10e879bb8",
   "metadata": {},
   "source": [
    "1. RAW DATA DOWNLOADING GENERAL SCRIPT | SPLIT 90 MB LARGER FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4bcf50-2ade-4878-856c-408e8a2a4691",
   "metadata": {},
   "source": [
    "    1.1. Creating the Contained Files Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546cf07e-808f-404e-97dc-9c421302d468",
   "metadata": {},
   "source": [
    "    This segment creates the folders that are going to contain the csv files of the powert plant data collected.\n",
    "    Notice that in order to keep the previous Dispa-SET directories sctructure is recomended to create a separated folder for each country; state; region; etc wanted to be simulated. e.g. In Next lines it is going to create a unique folder for Belgium country under the name \"BE\" according to the ISO 3166-1 standard.\n",
    "            names_line = \"Name1, Name2, Name3,... NameN\"\n",
    "            names_line = \"BE\"\n",
    "    However for more folders/countries just separe the names by comas \"\n",
    "            names_line = \"BE, AT, BG, CH,.....\"\n",
    "    Additionally indicate the path where folders are going to be storages. In order to keep the Dispa-SET directories structure, the defaoult path is allready set, just be needed to add the current path to the local dispa-SET repository\n",
    "            base_path = \"/Path/to/the/Local/Dispa-SET/Repository/RawData/PowerPlants/\n",
    "            base_path = \"/home/ray/Dispa-SET_Unleash/RawData/PowerPlants/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a6e121-d17f-44f4-b32c-7853ad564a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders created for names at: /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/\n"
     ]
    }
   ],
   "source": [
    "# Get the line of names (replace \"Name1, Name2,... NameN with the actual input)\n",
    "names_line = \"DE\"\n",
    "\n",
    "# Specify the base path for folders\n",
    "base_path = \"/home/ray/Dispa-SET_Unleash/RawData/PowerPlants/\"\n",
    "\n",
    "# Split the line into a list of names\n",
    "names = names_line.split(\", \")\n",
    "\n",
    "# Loop through each name and create a folder\n",
    "import os\n",
    "for name in names:\n",
    "  folder_name = name.strip()\n",
    "  # Combine base path and folder name\n",
    "  full_path = os.path.join(base_path, folder_name)\n",
    "  os.makedirs(full_path, exist_ok=True)\n",
    "\n",
    "print(f\"Folders created for names at: {base_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e2e354-684f-44a0-a87f-24237026030a",
   "metadata": {},
   "source": [
    "    1.2 Downloading and spliting large files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8567a-82e5-4c54-8ab1-576b39425147",
   "metadata": {},
   "source": [
    "    The following file permit to download from a portal web changing the url link as variable. Also permit to change the extension of the file modifiying by other desired e.g. .xlsx, .txt. etc. Permit to give an specified name to the file adding the suffix \"_part_1\" for a posterious data management purpouses. Finally permit to give the phat to a .csv file, that has to be previously created, to writedown the link sources. All this modifications can be done at the end of the code.\n",
    "    Finally for downloaded files larger than 90 MB, the code permit to split the original file into smaller files, because of posterior management purpouses as well, adding the \"_part_2\", \"_part_3\" and so on.\n",
    "    It is important to notice the code overwrite any previous existing file into the set directory if the same has the same name, to avoid problems it is recomended to make a backup of the already existing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942c2505-2b68-4054-8712-c304c42bf0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "def download_and_split_file(url, download_dir, user_filename, user_extension, csv_filepath):\n",
    "    \"\"\"Downloads the file, splits if larger than 100MB, and adds part suffixes (\"part_x\") before the extension.\n",
    "    Also writes filename and url to a CSV.\"\"\"\n",
    "\n",
    "    # INTRODUCE THE DESIRED NAME, THE EXTENSION, THE URL LINK AND THE STORAGE DIRECTORY OF THE FILE TO BE DOWNLOADED. ADDIOTANLLY SPECIFY THE SOURCES FILE PATH\n",
    "    user_filename = \"2020-01\"\n",
    "    user_extension = \".csv\"\n",
    "    url = \"https://data.open-power-system-data.org/conventional_power_plants/2020-10-01/conventional_power_plants_DE.csv\"\n",
    "    csv_filepath = \"/home/ray/Dispa-SET_Unleash/RawData/PowerPlants/DE/DE_Sources.csv\"\n",
    "    download_dir = \"/home/ray/Dispa-SET_Unleash/RawData/PowerPlants/DE\"\n",
    "\n",
    "    max_part_size = 90 * 1024 * 1024\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Construct filename with part suffix if needed\n",
    "        part_number = 1\n",
    "        filename = f\"{user_filename}_part_{part_number}{user_extension}\"\n",
    "    \n",
    "        # Download and split the file\n",
    "        downloaded_size = 0\n",
    "        with open(os.path.join(download_dir, filename), 'wb') as f:  # Open with full path\n",
    "            for chunk in response.iter_content(1024):\n",
    "                f.write(chunk)\n",
    "                downloaded_size += len(chunk)\n",
    "    \n",
    "                # Check if part size limit is reached or end of file is reached\n",
    "                if downloaded_size >= max_part_size or chunk == b'':\n",
    "                    f.close()  # Close the current file\n",
    "    \n",
    "                    if downloaded_size >= max_part_size:\n",
    "                        # Create a new file for the next part\n",
    "                        part_number += 1\n",
    "                        filename = f\"{user_filename}_part_{part_number}{user_extension}\"\n",
    "                        f = open(os.path.join(download_dir, filename), 'wb')\n",
    "                        downloaded_size = 0  # Reset downloaded size for next part\n",
    "    \n",
    "        # Write filename and url to CSV\n",
    "        try:\n",
    "            # Open in append mode to add a new row\n",
    "            with open(csv_filepath, 'a', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow([user_filename, url])\n",
    "            print(f\"Filename and URL written to CSV: {csv_filepath}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"CSV file not found: {csv_filepath}\")\n",
    "    \n",
    "        # Print successful download message\n",
    "        print(f\"File downloaded successfully: {os.path.join(download_dir, filename)}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"Error downloading file: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89180ac3-79e3-4c34-9936-6dd4fed81e48",
   "metadata": {},
   "source": [
    "    In order to keep the Dispa-SET directories files names structure, it is recommended to name the file with the year of the data. Aditionally, is comnun to find diferent sources separed into conventional and renewable power plant data, being posible to find more than a unique file to be proccessed, so, add a numerical suffix to the downloaded file \n",
    "        user_filename = \"20##-##\"\n",
    "    e.g. In the current code a power plants data file for Belgium in 2020 year is going to be downloaded:\n",
    "        user_filename = \"2020-01\"\n",
    "    So also for the download directory is recomended to download all power plant data into a folder named by the country; zone; state; or region wanted to be simulated, e.g.\n",
    "        download_dir = \"/home/ray/Dispa-SET_Unleash/RawData/PowerPlants/##\"\n",
    "        download_dir = \"/home/ray/Dispa-SET_Unleash/RawData/PowerPlants/BE\"\n",
    "    Use the same patron to create the csv file sources to save links of all donwloaded data, in this case:\n",
    "        csv_filepath = \"/home/ray/Dispa-SET_Unleash/RawData/PowerPlants/BE/20##_Sources.csv\"\n",
    "        csv_filepath = \"/home/ray/Dispa-SET_Unleash/RawData/PowerPlants/BE/2020_Sources.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
