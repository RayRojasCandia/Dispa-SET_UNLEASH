{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d142e2-90a8-44df-813b-387a490cc353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename and URL written to CSV: /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/downloaded_files.csv\n",
      "File downloaded successfully: /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/ConvensionalRenewablePowerPlants_EU_part_1.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "def download_and_split_file(url, download_dir, user_filename, user_extension):\n",
    "  \"\"\"Downloads the file, splits if larger than 100MB, and adds part suffixes (\"part_x\") before the extension.\n",
    "  Also writes filename and url to a CSV.\"\"\"\n",
    "\n",
    "  # Define variables (moved to the top for clarity)\n",
    "  max_part_size = 90 * 1024 * 1024\n",
    "\n",
    "  # Download the file\n",
    "  response = requests.get(url, stream=True)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    # Construct filename with part suffix if needed\n",
    "    part_number = 1\n",
    "    filename = f\"{user_filename}_part_{part_number}{user_extension}\"\n",
    "\n",
    "    # Download and split the file\n",
    "    downloaded_size = 0\n",
    "    with open(os.path.join(download_dir, filename), 'wb') as f:  # Open with full path\n",
    "      for chunk in response.iter_content(1024):\n",
    "        f.write(chunk)\n",
    "        downloaded_size += len(chunk)\n",
    "\n",
    "        # Check if part size limit is reached or end of file is reached\n",
    "        if downloaded_size >= max_part_size or chunk == b'':\n",
    "          f.close()  # Close the current file\n",
    "\n",
    "          if downloaded_size >= max_part_size:\n",
    "            # Create a new file for the next part\n",
    "            part_number += 1\n",
    "            filename = f\"{user_filename}_part_{part_number}{user_extension}\"\n",
    "            f = open(os.path.join(download_dir, filename), 'wb')\n",
    "            downloaded_size = 0  # Reset downloaded size for next part\n",
    "\n",
    "    # Write filename and url to CSV (assuming CSV exists)\n",
    "    csv_filepath = os.path.join(download_dir, \"downloaded_files.csv\")  # Replace with your CSV path\n",
    "    try:\n",
    "      # Open in append mode to add a new row\n",
    "      with open(csv_filepath, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([user_filename, url])\n",
    "      print(f\"Filename and URL written to CSV: {csv_filepath}\")\n",
    "    except FileNotFoundError:\n",
    "      print(f\"CSV file not found: {csv_filepath}\")\n",
    "\n",
    "    # Print successful download message (added back)\n",
    "    print(f\"File downloaded successfully: {os.path.join(download_dir, filename)}\")\n",
    "\n",
    "  else:\n",
    "    print(f\"Error downloading file: {response.status_code}\")\n",
    "\n",
    "# Download and write to CSV\n",
    "user_filename = \"ConvensionalRenewablePowerPlants_EU\"\n",
    "user_extension = \".csv\"\n",
    "url = \"https://data.open-power-system-data.org/conventional_power_plants/2020-10-01/conventional_power_plants_EU.csv\"\n",
    "download_dir = \"/home/ray/Dispa-SET_Unleash/RawData/PowerPlants\"\n",
    "download_and_split_file(url, download_dir, user_filename, user_extension)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
