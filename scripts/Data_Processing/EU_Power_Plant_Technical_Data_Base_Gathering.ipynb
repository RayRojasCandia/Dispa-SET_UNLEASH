{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da7565b4-facc-4357-a94f-368887ac1524",
   "metadata": {},
   "source": [
    "EUROPEAN POWER PLANT THECHNICAL DATA BASE CREATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dfefe5-2ef5-4f87-9899-5a1d9ec20881",
   "metadata": {},
   "source": [
    "This script use all the csv files of the  current Dispa-SET Power Plants Thechnical data base, as the starting point to extract the relevant and needed power units thechnical features that are used as inputs in the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dd0436-1591-4c51-9a8c-be11e0552e01",
   "metadata": {},
   "source": [
    "1. Creating a CSV with all the respective headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd54dca-90a1-4ba8-9fa0-1e5c413da238",
   "metadata": {},
   "source": [
    "This part create a clean csv file with all the headers (Power Units Technical Features) needed for Dispa-SET where all the data from all the files will be gathered on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef4d95-6b79-41ab-adf9-f4396a842c96",
   "metadata": {},
   "source": [
    "1.1. Enter the file where the headers want to be extracted and the path of the resulting file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e39743-4b53-4999-b09a-77183c853ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = '/home/ray/Dispa-SET/tests/dummy_data/Units_testcase.csv'\n",
    "output_file_path = '/home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1734d53c-a2e7-42db-af97-a103b2df5589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_csv_with_same_headers(input_file_path, output_file_path):\n",
    "    # Read the existing CSV file to get its headers\n",
    "    df = pd.read_csv(input_file_path)\n",
    "\n",
    "    # Extract headers from the DataFrame\n",
    "    headers = df.columns.tolist()\n",
    "\n",
    "    # Write the headers to a new CSV file\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        file.write(','.join(headers))\n",
    "\n",
    "create_csv_with_same_headers(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330c1b50-e0dc-4ab3-98f8-3a062aff47aa",
   "metadata": {},
   "source": [
    "2. Copying all the power units data related of an European country found in the Dipspa-SET Directories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ee11f1-529b-43b5-8741-03fbd0ef0b13",
   "metadata": {},
   "source": [
    "2.1 Enter the path of the folder where all the files wanted to be copied are stored, also enter the path of the file to be written on.\n",
    "\n",
    "    Remember run the folling two cells, changing the folder_path variable for each country of the dispa-SET data base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da4addaf-fea7-406f-be93-63de4069b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/AT'\n",
    "destination_file = output_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b75dd0-e14d-4bc1-a2df-e926c597f70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/AT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7326/3443183079.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
      "/tmp/ipykernel_7326/3443183079.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd549f36-b629-46ac-8ca3-7e498c1d9db5",
   "metadata": {},
   "source": [
    "Enter the directory path and the file path of the resulting file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a20cfae-4bc2-4e5e-9b8e-fe3759bf29a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/BE\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/BE'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d499d112-578b-480f-8505-ac2ac194f82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/BG\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/BG'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6b43ca4-4b6f-41cb-b3b3-0bbeb9e83cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/CH\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/CH'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9197612c-67a0-433f-9c59-49ffd66cdff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/CY\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/CY'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c55c02f3-2c5c-4f95-998c-7e0dbbd6bad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/CZ\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/CZ'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b6d2ab3-4f57-4109-a481-268c88850b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/DE\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/DE'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9acf9461-a1b8-49e8-a385-52b40cb4dd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/DK\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/DK'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82b5cb3b-dd9e-43ec-b0f3-2a5b900309a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/EE\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/EE'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6a28fc0-93ac-42ed-876d-e93190cf1c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/EL\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/EL'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e60a875-034f-44ed-8bd9-39b52c657693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/ES\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/ES'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b069edb-5086-464c-8a9a-3422c86e772c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/FI\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/FI'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f297201-ac1b-43cd-baae-151d8f9b5713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/FR\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/FR'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "813e3b6f-f1d3-4e52-9902-2f0623c8ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/HR\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/HR'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5ca6a93-d0ca-4e8a-b340-38301758ede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/HU\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/HU'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e87d286e-df33-4244-a069-39be5075a246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/IE\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/IE'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f803b27b-ee41-440c-8fc5-bc730e8ef39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/IT\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/IT'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d00cf6ca-a1bb-4587-ad78-92139b558801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/LT\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/LT'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1e8aa2f-c79d-48b7-923c-a8cd677e187f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/LU\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/LU'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb9ce395-7d35-4be6-aa74-dcb3a56007f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/LV\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/LV'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ed6c67e-e5b1-4106-8749-8f4ad95d7197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/NL\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/NL'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbfbe119-2935-4f72-96b5-b428aae14664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/NO\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/NO'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b447728e-f059-413e-a324-45b3a965d748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/PL\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/PL'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93a88222-eb58-4c31-a058-d1908ad09f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/PT\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/PT'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c89a678-8d88-4be2-8c0a-049ec7ed4066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/RO\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/RO'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3a42766-9dc2-401f-acea-1733c5e0e1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/SE\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/SE'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d02a3ee9-eee7-4a35-8bca-1ca7b88c4786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/SI\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/SI'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7d94b66-5013-4f6f-a81c-fd1f850d7211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/SK\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/SK'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ee1edd6-56e8-4d4b-8716-b5df2682443e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to /home/ray/Dispa-SET_Unleash/RawData/PowerPlants/Dictionaries/EU_Power_Units_Technical_Features/EU_Power_Units_Technical_Features.csv from files in /home/ray/Dispa-SET_Unleash/Database/PowerPlants/UK\n"
     ]
    }
   ],
   "source": [
    "source_folder = '/home/ray/Dispa-SET_Unleash/Database/PowerPlants/UK'\n",
    "destination_file = output_file_path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def copy_matching_columns(source_folder, destination_file):\n",
    "  \"\"\"\n",
    "  Copies columns with matching names from all CSV files in a folder to a destination file.\n",
    "\n",
    "  Args:\n",
    "      source_folder (str): Path to the folder containing CSV files.\n",
    "      destination_file (str): Path to the destination CSV file.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the destination file (assuming it exists)\n",
    "  try:\n",
    "    df_destination = pd.read_csv(destination_file)\n",
    "  except FileNotFoundError:\n",
    "    df_destination = None  # Create a new DataFrame if destination file doesn't exist\n",
    "\n",
    "  # Iterate through CSV files in the folder\n",
    "  for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      source_file = os.path.join(source_folder, filename)\n",
    "\n",
    "      # Read the source CSV file\n",
    "      try:\n",
    "        df_source = pd.read_csv(source_file)\n",
    "      except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        continue  # Skip files that don't exist or are empty\n",
    "\n",
    "      # Get columns with matching names\n",
    "      matching_columns = df_source.columns.intersection(df_destination.columns)\n",
    "      if matching_columns.empty:\n",
    "        continue  # Skip files with no matching columns\n",
    "\n",
    "      # Concatenate matching columns to the destination DataFrame (avoid duplicates)\n",
    "      df_destination = pd.concat([df_destination, df_source[matching_columns]], ignore_index=True)\n",
    "\n",
    "  # Save the updated destination DataFrame (if any data was appended)\n",
    "  if df_destination is not None:\n",
    "    df_destination.to_csv(destination_file, index=False)\n",
    "    print(f\"Data appended to {destination_file} from files in {source_folder}\")\n",
    "\n",
    "\n",
    "copy_matching_columns(source_folder, destination_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
